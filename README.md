# TRUZI_scan Training & Inference Pipeline

## Описание

Универсальный пайплайн для **обучения** и **инференса** модели для автоматического определения рака простаты с поддержкой:

- Обработки изображений (кадиррование, изменение контраста, SAM-сегментация)
- Настройки аугментаций
- Разделения датасета на обучающую и валидационную выборки по пациентам
- Использования `CUDA` или `CPU`


## Установка
Установите необходимые пакеты:

   pip install -r requirements.txt

При использовании GPU отдельно установите torch с поддержкой CUDA.


## Конфигурационный файл (`conf.json`)

Конфигурация состоит из двух разделов: `training` и `inference`.

### Общая структура:

```json
{
  "mode": "training",  // "training" или "inference"
  "training": { ... },
  "inference": { ... }
}
```

### Блок `"training"`

| Параметр                 | Описание                                                                 |
|--------------------------|--------------------------------------------------------------------------|
| `data_path`              | Путь к директории с папкой `images` с изображениями и папкой `labels` с аннотациями (формат YOLO). Файлы должны следовать правилу нейминга X_Y.расширение, где X - порядковый номер изображения, Y - порядковый номер пациента. Директория входных данных должна находиться в одной директории с `main.py`        |
| `epochs`                 | Количество эпох обучения.                                                |
| `batch_size`             | Размер батча.                                                            |
| `learning_rate`          | Начальный learning rate.                                                 |
| `img_size`               | Размер изображения.                                          |
| `pretrained`             | `true` — использовать модель, предобученную на ТРУЗИ снимках; `false` — начать с `yolov8n.pt`.        |
| `weights_save_path`      | Папка, куда сохраняются веса модели и лог обучения.                      |
| `validation_split`       | Доля данных, используемая для валидации (0.0–1.0).                       |
| `early_stopping`         | Включение ранней остановки.                                              |
| `early_stopping_patience`| Количество эпох без улучшения до остановки.                             |
| `augmentation`           | Включение пользовательских аугментаций.                                        |
| `augmentation_params`    | Настройки аугментаций (значения от 0.0 до 1.0).                          |
| `apply_crop`             | Кадрировать изображения перед обучением.                                 |
| `apply_contrast`         | Усиление контраста изображений перед обучением.                                     |
| `apply_sam`              | Применить SAM-сегментацию к изображениям перед обучением.                                |
| `original_image_size`    | Оригинальный размер изображения `[ширина, высота]`.                      |
| `crop_box`               | Область обрезки: `[x1, y1, x2, y2]`.                                     |
| `sam_checkpoint`         | Путь к чекпойнту SAM-модели.                                             |
| `model_type`             | Тип SAM-модели (`vit_l`, `vit_h`, `vit_b`).                               |
| `device`                 | Устройство для обучения: `"cuda"` или `"cpu"`.                          |


### Блок `"inference"`

| Параметр              | Описание                                                                 |
|------------------------|--------------------------------------------------------------------------|
| `model_path`           | Путь к `.pt` файлу модели.                                               |
| `image_path`           | Путь к директории с папкой images с изображениям для инференса. Директория входных данных должна находиться в одной директории с `main.py`                                      |
| `output_path`          | Папка для сохранения результатов.                                       |
| `confidence_threshold` | Порог уверенности (от 0 до 1).                                          |
| `iou_threshold`        | Порог IoU для NMS.                                                       |
| `show_results`         | Показывать изображения с результатами.                                  |
| `save_results`         | Сохранять изображения с предсказаниями.                                 |
| `apply_crop`           | Кадрировать изображения перед инференсом.                                     |
| `apply_contrast`       | Усиление контраста изображений перед инференсом.                                                      |
| `apply_sam`            | Применить SAM-сегментацию к изображениям перед инференсом.                                              |
| `original_image_size`  | Размер оригинальных изображений `[ширина, высота]`.                     |
| `crop_box`             | Область обрезки: `[x1, y1, x2, y2]`.                                     |
| `sam_checkpoint`       | Путь к чекпойнту SAM-модели.                                             |
| `model_type`           | Тип SAM-модели (`vit_l`, `vit_h`, `vit_b`).                              |
| `device`               | Устройство для инференса: `"cuda"` или `"cpu"`.                         |

### Чекпоинты SAM

Файлы чекпоинтов модели SAM можно найти по ссылке: https://github.com/facebookresearch/segment-anything?tab=readme-ov-file

### Запуск

Вам, предварительно установив все необходимые пакеты, а также подготовив файл конфигурации `conf.json` под ваш случай, нужно запустить файл `main.py`. Данная программа выводит статусы работы, так что можно отслеживать, на каком именно этапе она сейчас находится.
