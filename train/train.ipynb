{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "KZWgGOGjU4mP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22kny4hOGPND",
        "outputId": "cd0a0f02-1a40-4c33-9f54-5fe5a41545af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import yaml\n",
        "import shutil\n",
        "import cv2\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_-sDg9_hGZIq",
        "outputId": "db9317d4-3567-40de-aa78-26a0099dda47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.40-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.40-py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.40 ultralytics-thop-2.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E658V_MHHQM1",
        "outputId": "7fb1908a-3b7c-4749-8cc9-6754b3cd5602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/prostate_cancer/YOLO_sech_1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rmX4KEAHLXy",
        "outputId": "2a5abf3a-d423-40ed-e873-993d1c559da3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/prostate_cancer/YOLO_sech_1.zip\n",
            "   creating: YOLO_sech_1/\n",
            "  inflating: YOLO_sech_1/conf.yaml   \n",
            "   creating: YOLO_sech_1/images/\n",
            "  inflating: YOLO_sech_1/images/0.jpg  \n",
            "  inflating: YOLO_sech_1/images/1.jpg  \n",
            "  inflating: YOLO_sech_1/images/10.jpg  \n",
            "  inflating: YOLO_sech_1/images/11.jpg  \n",
            "  inflating: YOLO_sech_1/images/12.jpg  \n",
            "  inflating: YOLO_sech_1/images/13.jpg  \n",
            "  inflating: YOLO_sech_1/images/14.jpg  \n",
            "  inflating: YOLO_sech_1/images/15.jpg  \n",
            "  inflating: YOLO_sech_1/images/16.jpg  \n",
            "  inflating: YOLO_sech_1/images/17.jpg  \n",
            "  inflating: YOLO_sech_1/images/18.jpg  \n",
            "  inflating: YOLO_sech_1/images/19.jpg  \n",
            "  inflating: YOLO_sech_1/images/2.jpg  \n",
            "  inflating: YOLO_sech_1/images/20.jpg  \n",
            "  inflating: YOLO_sech_1/images/21.jpg  \n",
            "  inflating: YOLO_sech_1/images/22.jpg  \n",
            "  inflating: YOLO_sech_1/images/23.jpg  \n",
            "  inflating: YOLO_sech_1/images/24.jpg  \n",
            "  inflating: YOLO_sech_1/images/25.jpg  \n",
            "  inflating: YOLO_sech_1/images/26.jpg  \n",
            "  inflating: YOLO_sech_1/images/27.jpg  \n",
            "  inflating: YOLO_sech_1/images/28.jpg  \n",
            "  inflating: YOLO_sech_1/images/29.jpg  \n",
            "  inflating: YOLO_sech_1/images/3.jpg  \n",
            "  inflating: YOLO_sech_1/images/30.jpg  \n",
            "  inflating: YOLO_sech_1/images/31.jpg  \n",
            "  inflating: YOLO_sech_1/images/32.jpg  \n",
            "  inflating: YOLO_sech_1/images/33.jpg  \n",
            "  inflating: YOLO_sech_1/images/34.jpg  \n",
            "  inflating: YOLO_sech_1/images/35.jpg  \n",
            "  inflating: YOLO_sech_1/images/36.jpg  \n",
            "  inflating: YOLO_sech_1/images/37.jpg  \n",
            "  inflating: YOLO_sech_1/images/38.jpg  \n",
            "  inflating: YOLO_sech_1/images/39.jpg  \n",
            "  inflating: YOLO_sech_1/images/4.jpg  \n",
            "  inflating: YOLO_sech_1/images/40.jpg  \n",
            "  inflating: YOLO_sech_1/images/41.jpg  \n",
            "  inflating: YOLO_sech_1/images/42.jpg  \n",
            "  inflating: YOLO_sech_1/images/43.jpg  \n",
            "  inflating: YOLO_sech_1/images/44.jpg  \n",
            "  inflating: YOLO_sech_1/images/45.jpg  \n",
            "  inflating: YOLO_sech_1/images/46.jpg  \n",
            "  inflating: YOLO_sech_1/images/47.jpg  \n",
            "  inflating: YOLO_sech_1/images/48.jpg  \n",
            "  inflating: YOLO_sech_1/images/49.jpg  \n",
            "  inflating: YOLO_sech_1/images/5.jpg  \n",
            "  inflating: YOLO_sech_1/images/50.jpg  \n",
            "  inflating: YOLO_sech_1/images/51.jpg  \n",
            "  inflating: YOLO_sech_1/images/52.jpg  \n",
            "  inflating: YOLO_sech_1/images/53.jpg  \n",
            "  inflating: YOLO_sech_1/images/54.jpg  \n",
            "  inflating: YOLO_sech_1/images/55.jpg  \n",
            "  inflating: YOLO_sech_1/images/56.jpg  \n",
            "  inflating: YOLO_sech_1/images/57.jpg  \n",
            "  inflating: YOLO_sech_1/images/58.jpg  \n",
            "  inflating: YOLO_sech_1/images/59.jpg  \n",
            "  inflating: YOLO_sech_1/images/6.jpg  \n",
            "  inflating: YOLO_sech_1/images/60.jpg  \n",
            "  inflating: YOLO_sech_1/images/61.jpg  \n",
            "  inflating: YOLO_sech_1/images/62.jpg  \n",
            "  inflating: YOLO_sech_1/images/63.jpg  \n",
            "  inflating: YOLO_sech_1/images/64.jpg  \n",
            "  inflating: YOLO_sech_1/images/65.jpg  \n",
            "  inflating: YOLO_sech_1/images/66.jpg  \n",
            "  inflating: YOLO_sech_1/images/67.jpg  \n",
            "  inflating: YOLO_sech_1/images/68.jpg  \n",
            "  inflating: YOLO_sech_1/images/69.jpg  \n",
            "  inflating: YOLO_sech_1/images/7.jpg  \n",
            "  inflating: YOLO_sech_1/images/70.jpg  \n",
            "  inflating: YOLO_sech_1/images/71.jpg  \n",
            "  inflating: YOLO_sech_1/images/72.jpg  \n",
            "  inflating: YOLO_sech_1/images/73.jpg  \n",
            "  inflating: YOLO_sech_1/images/74.jpg  \n",
            "  inflating: YOLO_sech_1/images/75.jpg  \n",
            "  inflating: YOLO_sech_1/images/76.jpg  \n",
            "  inflating: YOLO_sech_1/images/77.jpg  \n",
            "  inflating: YOLO_sech_1/images/78.jpg  \n",
            "  inflating: YOLO_sech_1/images/79.jpg  \n",
            "  inflating: YOLO_sech_1/images/8.jpg  \n",
            "  inflating: YOLO_sech_1/images/9.jpg  \n",
            "   creating: YOLO_sech_1/labels/\n",
            "  inflating: YOLO_sech_1/labels/0.txt  \n",
            "  inflating: YOLO_sech_1/labels/1.txt  \n",
            "  inflating: YOLO_sech_1/labels/10.txt  \n",
            "  inflating: YOLO_sech_1/labels/11.txt  \n",
            "  inflating: YOLO_sech_1/labels/12.txt  \n",
            "  inflating: YOLO_sech_1/labels/13.txt  \n",
            "  inflating: YOLO_sech_1/labels/14.txt  \n",
            "  inflating: YOLO_sech_1/labels/15.txt  \n",
            "  inflating: YOLO_sech_1/labels/16.txt  \n",
            "  inflating: YOLO_sech_1/labels/17.txt  \n",
            "  inflating: YOLO_sech_1/labels/18.txt  \n",
            "  inflating: YOLO_sech_1/labels/19.txt  \n",
            "  inflating: YOLO_sech_1/labels/2.txt  \n",
            "  inflating: YOLO_sech_1/labels/20.txt  \n",
            "  inflating: YOLO_sech_1/labels/21.txt  \n",
            "  inflating: YOLO_sech_1/labels/22.txt  \n",
            "  inflating: YOLO_sech_1/labels/23.txt  \n",
            "  inflating: YOLO_sech_1/labels/24.txt  \n",
            "  inflating: YOLO_sech_1/labels/25.txt  \n",
            "  inflating: YOLO_sech_1/labels/26.txt  \n",
            "  inflating: YOLO_sech_1/labels/27.txt  \n",
            "  inflating: YOLO_sech_1/labels/28.txt  \n",
            "  inflating: YOLO_sech_1/labels/29.txt  \n",
            "  inflating: YOLO_sech_1/labels/3.txt  \n",
            "  inflating: YOLO_sech_1/labels/30.txt  \n",
            "  inflating: YOLO_sech_1/labels/31.txt  \n",
            "  inflating: YOLO_sech_1/labels/32.txt  \n",
            "  inflating: YOLO_sech_1/labels/33.txt  \n",
            "  inflating: YOLO_sech_1/labels/34.txt  \n",
            "  inflating: YOLO_sech_1/labels/35.txt  \n",
            "  inflating: YOLO_sech_1/labels/36.txt  \n",
            "  inflating: YOLO_sech_1/labels/37.txt  \n",
            "  inflating: YOLO_sech_1/labels/38.txt  \n",
            "  inflating: YOLO_sech_1/labels/39.txt  \n",
            "  inflating: YOLO_sech_1/labels/4.txt  \n",
            "  inflating: YOLO_sech_1/labels/40.txt  \n",
            "  inflating: YOLO_sech_1/labels/41.txt  \n",
            "  inflating: YOLO_sech_1/labels/42.txt  \n",
            "  inflating: YOLO_sech_1/labels/43.txt  \n",
            "  inflating: YOLO_sech_1/labels/44.txt  \n",
            "  inflating: YOLO_sech_1/labels/45.txt  \n",
            "  inflating: YOLO_sech_1/labels/46.txt  \n",
            "  inflating: YOLO_sech_1/labels/47.txt  \n",
            "  inflating: YOLO_sech_1/labels/48.txt  \n",
            "  inflating: YOLO_sech_1/labels/49.txt  \n",
            "  inflating: YOLO_sech_1/labels/5.txt  \n",
            "  inflating: YOLO_sech_1/labels/50.txt  \n",
            "  inflating: YOLO_sech_1/labels/51.txt  \n",
            "  inflating: YOLO_sech_1/labels/52.txt  \n",
            "  inflating: YOLO_sech_1/labels/53.txt  \n",
            "  inflating: YOLO_sech_1/labels/54.txt  \n",
            "  inflating: YOLO_sech_1/labels/55.txt  \n",
            "  inflating: YOLO_sech_1/labels/56.txt  \n",
            "  inflating: YOLO_sech_1/labels/57.txt  \n",
            "  inflating: YOLO_sech_1/labels/58.txt  \n",
            "  inflating: YOLO_sech_1/labels/59.txt  \n",
            "  inflating: YOLO_sech_1/labels/6.txt  \n",
            "  inflating: YOLO_sech_1/labels/60.txt  \n",
            "  inflating: YOLO_sech_1/labels/61.txt  \n",
            "  inflating: YOLO_sech_1/labels/62.txt  \n",
            "  inflating: YOLO_sech_1/labels/63.txt  \n",
            "  inflating: YOLO_sech_1/labels/64.txt  \n",
            "  inflating: YOLO_sech_1/labels/65.txt  \n",
            "  inflating: YOLO_sech_1/labels/66.txt  \n",
            "  inflating: YOLO_sech_1/labels/67.txt  \n",
            " extracting: YOLO_sech_1/labels/68.txt  \n",
            " extracting: YOLO_sech_1/labels/69.txt  \n",
            "  inflating: YOLO_sech_1/labels/7.txt  \n",
            " extracting: YOLO_sech_1/labels/70.txt  \n",
            " extracting: YOLO_sech_1/labels/71.txt  \n",
            " extracting: YOLO_sech_1/labels/72.txt  \n",
            " extracting: YOLO_sech_1/labels/73.txt  \n",
            " extracting: YOLO_sech_1/labels/74.txt  \n",
            " extracting: YOLO_sech_1/labels/75.txt  \n",
            " extracting: YOLO_sech_1/labels/76.txt  \n",
            " extracting: YOLO_sech_1/labels/77.txt  \n",
            " extracting: YOLO_sech_1/labels/78.txt  \n",
            " extracting: YOLO_sech_1/labels/79.txt  \n",
            "  inflating: YOLO_sech_1/labels/8.txt  \n",
            "  inflating: YOLO_sech_1/labels/9.txt  \n",
            "   creating: YOLO_sech_1/train/\n",
            "   creating: YOLO_sech_1/train/images/\n",
            "  inflating: YOLO_sech_1/train/images/0.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/11.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/12.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/13.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/14.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/15.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/16.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/18.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/19.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/2.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/20.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/21.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/22.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/23.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/25.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/26.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/27.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/28.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/29.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/30.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/33.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/34.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/35.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/37.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/39.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/4.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/40.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/41.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/42.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/43.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/45.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/46.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/47.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/48.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/49.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/5.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/51.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/52.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/53.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/55.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/56.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/57.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/58.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/59.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/6.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/60.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/61.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/62.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/63.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/65.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/67.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/68.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/69.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/7.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/70.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/71.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/72.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/74.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/75.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/76.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/77.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/78.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/8.jpg  \n",
            "  inflating: YOLO_sech_1/train/images/9.jpg  \n",
            "   creating: YOLO_sech_1/train/labels/\n",
            "  inflating: YOLO_sech_1/train/labels/0.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/11.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/12.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/13.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/14.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/15.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/16.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/18.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/19.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/2.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/20.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/21.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/22.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/23.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/25.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/26.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/27.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/28.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/29.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/30.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/33.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/34.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/35.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/37.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/39.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/4.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/40.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/41.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/42.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/43.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/45.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/46.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/47.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/48.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/49.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/5.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/51.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/52.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/53.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/55.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/56.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/57.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/58.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/59.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/6.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/60.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/61.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/62.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/63.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/65.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/67.txt  \n",
            " extracting: YOLO_sech_1/train/labels/68.txt  \n",
            " extracting: YOLO_sech_1/train/labels/69.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/7.txt  \n",
            " extracting: YOLO_sech_1/train/labels/70.txt  \n",
            " extracting: YOLO_sech_1/train/labels/71.txt  \n",
            " extracting: YOLO_sech_1/train/labels/72.txt  \n",
            " extracting: YOLO_sech_1/train/labels/74.txt  \n",
            " extracting: YOLO_sech_1/train/labels/75.txt  \n",
            " extracting: YOLO_sech_1/train/labels/76.txt  \n",
            " extracting: YOLO_sech_1/train/labels/77.txt  \n",
            " extracting: YOLO_sech_1/train/labels/78.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/8.txt  \n",
            "  inflating: YOLO_sech_1/train/labels/9.txt  \n",
            "   creating: YOLO_sech_1/val/\n",
            "   creating: YOLO_sech_1/val/images/\n",
            "  inflating: YOLO_sech_1/val/images/1.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/10.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/17.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/24.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/3.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/31.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/32.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/36.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/38.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/44.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/50.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/54.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/64.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/66.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/73.jpg  \n",
            "  inflating: YOLO_sech_1/val/images/79.jpg  \n",
            "   creating: YOLO_sech_1/val/labels/\n",
            "  inflating: YOLO_sech_1/val/labels/1.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/10.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/17.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/24.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/3.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/31.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/32.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/36.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/38.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/44.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/50.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/54.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/64.txt  \n",
            "  inflating: YOLO_sech_1/val/labels/66.txt  \n",
            " extracting: YOLO_sech_1/val/labels/73.txt  \n",
            " extracting: YOLO_sech_1/val/labels/79.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with folds"
      ],
      "metadata": {
        "id": "KZWgGOGjU4mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_config_path = \"conf_collab.yaml\"\n",
        "\n",
        "k_folds = 5\n",
        "epochs = 10\n",
        "img_size = 1024\n",
        "\n",
        "with open(data_config_path) as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "\n",
        "dataset_path = data_config['path']\n",
        "\n",
        "images_path = os.path.join(dataset_path, 'images')\n",
        "print(images_path)\n",
        "labels_path = os.path.join(dataset_path, 'labels')\n",
        "\n",
        "\n",
        "image_files = []\n",
        "image_files.extend(glob.glob(os.path.join(images_path, '*.jpg')))\n",
        "\n",
        "label_files = []\n",
        "label_files.extend(glob.glob(os.path.join(labels_path, '*.txt')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QF-TpWGGnbw",
        "outputId": "8a33d052-fc4d-4553-fb84-8b1b3284c6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLO_sech_1/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(image_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1okQfT6I525",
        "outputId": "5a8fdec9-4a3f-4fd9-9362-50bba0f68488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(fold_config_path, 'w') as f:\n",
        "        yaml.dump(fold_data_config, f)\n",
        "\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    model.train(data=fold_config_path, epochs=epochs, imgsz=img_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Iu4Nn-38Ulcu",
        "outputId": "318395fc-82cc-4265-9065-e1ef11decae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    model = YOLO(\"yolov8n.pt\")  # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(image_files)):\n",
        "    print(f'FOLD {fold + 1}/{k_folds}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    train_dir = os.path.join(dataset_path, 'images', f'fold_{fold}_train')\n",
        "    val_dir = os.path.join(dataset_path, 'images', f'fold_{fold}_val')\n",
        "    train_labels_dir = os.path.join(dataset_path, 'labels', f'fold_{fold}_train')\n",
        "    val_labels_dir = os.path.join(dataset_path, 'labels', f'fold_{fold}_val')\n",
        "\n",
        "    for directory in [train_dir, val_dir, train_labels_dir, val_labels_dir]:\n",
        "        if os.path.exists(directory):\n",
        "            shutil.rmtree(directory)\n",
        "\n",
        "    os.makedirs(train_dir)\n",
        "    os.makedirs(val_dir)\n",
        "    os.makedirs(train_labels_dir)\n",
        "    os.makedirs(val_labels_dir)\n",
        "\n",
        "    for idx in train_idx:\n",
        "        shutil.copy(image_files[idx], train_dir)\n",
        "        label_file = os.path.splitext(os.path.basename(image_files[idx]))[0] + '.txt'\n",
        "        shutil.copy(os.path.join(labels_path, label_file), train_labels_dir)\n",
        "\n",
        "    for idx in val_idx:\n",
        "        shutil.copy(image_files[idx], val_dir)\n",
        "        label_file = os.path.splitext(os.path.basename(image_files[idx]))[0] + '.txt'\n",
        "        shutil.copy(os.path.join(labels_path, label_file), val_labels_dir)\n",
        "\n",
        "    fold_config_path = os.path.join(dataset_path, f'fold_{fold}_config.yaml')\n",
        "    fold_data_config = data_config.copy()\n",
        "    fold_data_config['train'] = train_dir\n",
        "    fold_data_config['val'] = val_dir\n",
        "\n",
        "    with open(fold_config_path, 'w') as f:\n",
        "        yaml.dump(fold_data_config, f)\n",
        "\n",
        "\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    model.train(data=fold_config_path, epochs=epochs, imgsz=img_size)\n",
        "\n",
        "    model.save(f'yolo_model_fold_{fold}.pt')\n",
        "\n",
        "print('K-Fold Cross Validation Completed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aRhOW3uEIs-0",
        "outputId": "b528ab4e-8d93-4f3c-b6fc-4c65f9a106cc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1/5\n",
            "--------------------------------\n",
            "Ultralytics 8.3.38 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/YOLO_sech_1/fold_0_config.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/YOLO_sech_1/labels/fold_0_train... 54 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [00:00<00:00, 1660.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/YOLO_sech_1/labels/fold_0_train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLO_sech_1/labels/fold_0_val... 14 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:00<00:00, 568.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/YOLO_sech_1/labels/fold_0_val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTracingCheckError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/callbacks/tensorboard.py\u001b[0m in \u001b[0;36m_log_tensorboard_graph\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# place in .eval() mode to avoid BatchNorm statistics changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mWRITER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{PREFIX}model graph visualization added ‚úÖ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m     traced_func = _trace_impl(\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_trace_impl\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"example_kwarg_inputs should be a dict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         return trace_module(\n\u001b[0m\u001b[1;32m    699\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                     _check_trace(\n\u001b[0m\u001b[1;32m   1307\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_check_trace\u001b[0;34m(check_inputs, func, traced_func, check_tolerance, strict, force_outplace, is_trace_module, _module_class, example_inputs_is_kwarg)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiag_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTracingCheckError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiag_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTracingCheckError\u001b[0m: Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%self.1 : __torch__.ultralytics.nn.tasks.DetectionModel,\n\t\t        %x.1 : Tensor):\n\t\t    %model : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_22 : __torch__.ultralytics.nn.modules.head.Detect = prim::GetAttr[name=\"22\"](%model)\n\t\t    %model.45 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_21 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"21\"](%model.45)\n\t\t    %model.43 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_20 : __torch__.ultralytics.nn.modules.conv.Concat = prim::GetAttr[name=\"20\"](%model.43)\n\t\t    %model.41 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_19 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"19\"](%model.41)\n\t\t    %model.39 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_18 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"18\"](%model.39)\n\t\t    %model.37 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_17 : __torch__.ultralytics.nn.modules.conv.Concat = prim::GetAttr[name=\"17\"](%model.37)\n\t\t    %model.35 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_16 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"16\"](%model.35)\n\t\t    %model.33 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_15 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"15\"](%model.33)\n\t\t    %model.31 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_14 : __torch__.ultralytics.nn.modules.conv.Concat = prim::GetAttr[name=\"14\"](%model.31)\n\t\t    %model.29 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_13 : __torch__.torch.nn.modules.upsampling.Upsample = prim::GetAttr[name=\"13\"](%model.29)\n\t\t    %model.27 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_12 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"12\"](%model.27)\n\t\t    %model.25 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_11 : __torch__.ultralytics.nn.modules.conv.Concat = prim::GetAttr[name=\"11\"](%model.25)\n\t\t    %model.23 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_10 : __torch__.torch.nn.modules.upsampling.Upsample = prim::GetAttr[name=\"10\"](%model.23)\n\t\t    %model.21 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_9 : __torch__.ultralytics.nn.modules.block.SPPF = prim::GetAttr[name=\"9\"](%model.21)\n\t\t    %model.19 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_8 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"8\"](%model.19)\n\t\t    %model.17 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_7 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"7\"](%model.17)\n\t\t    %model.15 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_6 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"6\"](%model.15)\n\t\t    %model.13 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_5 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"5\"](%model.13)\n\t\t    %model.11 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_4 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"4\"](%model.11)\n\t\t    %model.9 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_3 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"3\"](%model.9)\n\t\t    %model.7 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_2.3 : __torch__.ultralytics.nn.modules.block.C2f = prim::GetAttr[name=\"2\"](%model.7)\n\t\t    %model.5 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_1.3 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%model.5)\n\t\t    %model.3 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_22.1 : __torch__.ultralytics.nn.modules.head.Detect = prim::GetAttr[name=\"22\"](%model.3)\n\t\t    %cv3.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"cv3\"](%_22.1)\n\t\t    %_2.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"2\"](%cv3.1)\n\t\t    %_1.1 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%_2.1)\n\t\t    %act.1 : __torch__.torch.nn.modules.activation.SiLU = prim::GetAttr[name=\"act\"](%_1.1)\n\t\t    %model.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t    %_0.1 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"0\"](%model.1)\n\t\t    %83 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.0/__module.model.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %84 : float = prim::Constant[value=0.001](), scope: __module.model.0/__module.model.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %85 : NoneType = prim::Constant(), scope: __module.model.0/__module.model.0.conv\n\t\t    %86 : int = prim::Constant[value=2](), scope: __module.model.0/__module.model.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %87 : int = prim::Constant[value=1](), scope: __module.model.0/__module.model.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %88 : bool = prim::Constant[value=0](), scope: __module.model.0/__module.model.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %89 : int = prim::Constant[value=0](), scope: __module.model.0/__module.model.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %90 : bool = prim::Constant[value=1](), scope: __module.model.0/__module.model.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %bn.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_0.1)\n\t\t    %conv.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_0.1)\n\t\t    %weight.243 : Tensor = prim::GetAttr[name=\"weight\"](%conv.1)\n\t\t    %94 : int[] = prim::ListConstruct(%86, %86), scope: __module.model.0/__module.model.0.conv\n\t\t    %95 : int[] = prim::ListConstruct(%87, %87), scope: __module.model.0/__module.model.0.conv\n\t\t    %96 : int[] = prim::ListConstruct(%87, %87), scope: __module.model.0/__module.model.0.conv\n\t\t    %97 : int[] = prim::ListConstruct(%89, %89), scope: __module.model.0/__module.model.0.conv\n\t\t    %input.1 : Tensor = aten::_convolution(%x.1, %weight.243, %85, %94, %95, %96, %88, %97, %87, %88, %90, %90, %90), scope: __module.model.0/__module.model.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.115 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.1)\n\t\t    %running_mean.115 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.1)\n\t\t    %bias.127 : Tensor = prim::GetAttr[name=\"bias\"](%bn.1)\n\t\t    %weight.245 : Tensor = prim::GetAttr[name=\"weight\"](%bn.1)\n\t\t    %input.3 : Tensor = aten::batch_norm(%input.1, %weight.245, %bias.127, %running_mean.115, %running_var.115, %88, %83, %84, %90), scope: __module.model.0/__module.model.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.5 : Tensor = aten::silu_(%input.3), scope: __module.model.0/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %105 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.1/__module.model.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %106 : float = prim::Constant[value=0.001](), scope: __module.model.1/__module.model.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %107 : NoneType = prim::Constant(), scope: __module.model.1/__module.model.1.conv\n\t\t    %108 : int = prim::Constant[value=2](), scope: __module.model.1/__module.model.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %109 : int = prim::Constant[value=1](), scope: __module.model.1/__module.model.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %110 : bool = prim::Constant[value=0](), scope: __module.model.1/__module.model.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %111 : int = prim::Constant[value=0](), scope: __module.model.1/__module.model.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %112 : bool = prim::Constant[value=1](), scope: __module.model.1/__module.model.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %bn.3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_1.3)\n\t\t    %conv.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_1.3)\n\t\t    %weight.247 : Tensor = prim::GetAttr[name=\"weight\"](%conv.3)\n\t\t    %116 : int[] = prim::ListConstruct(%108, %108), scope: __module.model.1/__module.model.1.conv\n\t\t    %117 : int[] = prim::ListConstruct(%109, %109), scope: __module.model.1/__module.model.1.conv\n\t\t    %118 : int[] = prim::ListConstruct(%109, %109), scope: __module.model.1/__module.model.1.conv\n\t\t    %119 : int[] = prim::ListConstruct(%111, %111), scope: __module.model.1/__module.model.1.conv\n\t\t    %input.7 : Tensor = aten::_convolution(%input.5, %weight.247, %107, %116, %117, %118, %110, %119, %109, %110, %112, %112, %112), scope: __module.model.1/__module.model.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.117 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.3)\n\t\t    %running_mean.117 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.3)\n\t\t    %bias.129 : Tensor = prim::GetAttr[name=\"bias\"](%bn.3)\n\t\t    %weight.249 : Tensor = prim::GetAttr[name=\"weight\"](%bn.3)\n\t\t    %input.9 : Tensor = aten::batch_norm(%input.7, %weight.249, %bias.129, %running_mean.117, %running_var.117, %110, %105, %106, %112), scope: __module.model.1/__module.model.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.11 : Tensor = aten::silu_(%input.9), scope: __module.model.1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %127 : int = prim::Constant[value=2](), scope: __module.model.2 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %128 : bool = prim::Constant[value=1](), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %129 : bool = prim::Constant[value=0](), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %130 : int = prim::Constant[value=0](), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %131 : int = prim::Constant[value=1](), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %132 : NoneType = prim::Constant(), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv\n\t\t    %133 : float = prim::Constant[value=0.001](), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %134 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.3 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_2.3)\n\t\t    %m.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_2.3)\n\t\t    %_0.3 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m.1)\n\t\t    %cv1.1 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_2.3)\n\t\t    %bn.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.1)\n\t\t    %conv.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.1)\n\t\t    %weight.251 : Tensor = prim::GetAttr[name=\"weight\"](%conv.5)\n\t\t    %142 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv\n\t\t    %143 : int[] = prim::ListConstruct(%130, %130), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv\n\t\t    %144 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv\n\t\t    %145 : int[] = prim::ListConstruct(%130, %130), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv\n\t\t    %input.13 : Tensor = aten::_convolution(%input.11, %weight.251, %132, %142, %143, %144, %129, %145, %131, %129, %128, %128, %128), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.119 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.5)\n\t\t    %running_mean.119 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.5)\n\t\t    %bias.131 : Tensor = prim::GetAttr[name=\"bias\"](%bn.5)\n\t\t    %weight.253 : Tensor = prim::GetAttr[name=\"weight\"](%bn.5)\n\t\t    %input.15 : Tensor = aten::batch_norm(%input.13, %weight.253, %bias.131, %running_mean.119, %running_var.119, %129, %134, %133, %128), scope: __module.model.2/__module.model.2.cv1/__module.model.2.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %152 : Tensor = aten::silu_(%input.15), scope: __module.model.2/__module.model.2.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %153 : Tensor[] = aten::chunk(%152, %127, %131), scope: __module.model.2 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %154 : Tensor, %input.17 : Tensor = prim::ListUnpack(%153), scope: __module.model.2\n\t\t    %cv2.1 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.3)\n\t\t    %cv1.3 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.3)\n\t\t    %bn.7 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.3)\n\t\t    %conv.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.3)\n\t\t    %weight.255 : Tensor = prim::GetAttr[name=\"weight\"](%conv.7)\n\t\t    %161 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv1/__module.model.2.m.0.cv1.conv\n\t\t    %162 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv1/__module.model.2.m.0.cv1.conv\n\t\t    %163 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv1/__module.model.2.m.0.cv1.conv\n\t\t    %164 : int[] = prim::ListConstruct(%130, %130), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv1/__module.model.2.m.0.cv1.conv\n\t\t    %input.19 : Tensor = aten::_convolution(%input.17, %weight.255, %132, %161, %162, %163, %129, %164, %131, %129, %128, %128, %128), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv1/__module.model.2.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.121 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.7)\n\t\t    %running_mean.121 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.7)\n\t\t    %bias.133 : Tensor = prim::GetAttr[name=\"bias\"](%bn.7)\n\t\t    %weight.257 : Tensor = prim::GetAttr[name=\"weight\"](%bn.7)\n\t\t    %input.21 : Tensor = aten::batch_norm(%input.19, %weight.257, %bias.133, %running_mean.121, %running_var.121, %129, %134, %133, %128), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv1/__module.model.2.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.23 : Tensor = aten::silu_(%input.21), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.9 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.1)\n\t\t    %conv.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.1)\n\t\t    %weight.259 : Tensor = prim::GetAttr[name=\"weight\"](%conv.9)\n\t\t    %175 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv2/__module.model.2.m.0.cv2.conv\n\t\t    %176 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv2/__module.model.2.m.0.cv2.conv\n\t\t    %177 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv2/__module.model.2.m.0.cv2.conv\n\t\t    %178 : int[] = prim::ListConstruct(%130, %130), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv2/__module.model.2.m.0.cv2.conv\n\t\t    %input.25 : Tensor = aten::_convolution(%input.23, %weight.259, %132, %175, %176, %177, %129, %178, %131, %129, %128, %128, %128), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv2/__module.model.2.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.123 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.9)\n\t\t    %running_mean.123 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.9)\n\t\t    %bias.135 : Tensor = prim::GetAttr[name=\"bias\"](%bn.9)\n\t\t    %weight.261 : Tensor = prim::GetAttr[name=\"weight\"](%bn.9)\n\t\t    %input.27 : Tensor = aten::batch_norm(%input.25, %weight.261, %bias.135, %running_mean.123, %running_var.123, %129, %134, %133, %128), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv2/__module.model.2.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %185 : Tensor = aten::silu_(%input.27), scope: __module.model.2/__module.model.2.m.0/__module.model.2.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %186 : Tensor = aten::add(%input.17, %185, %131), scope: __module.model.2/__module.model.2.m.0 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:347:0\n\t\t    %187 : Tensor[] = prim::ListConstruct(%154, %input.17, %186), scope: __module.model.2\n\t\t    %input.29 : Tensor = aten::cat(%187, %131), scope: __module.model.2 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.11 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.3)\n\t\t    %conv.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.3)\n\t\t    %weight.263 : Tensor = prim::GetAttr[name=\"weight\"](%conv.11)\n\t\t    %192 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.cv2/__module.model.2.cv2.conv\n\t\t    %193 : int[] = prim::ListConstruct(%130, %130), scope: __module.model.2/__module.model.2.cv2/__module.model.2.cv2.conv\n\t\t    %194 : int[] = prim::ListConstruct(%131, %131), scope: __module.model.2/__module.model.2.cv2/__module.model.2.cv2.conv\n\t\t    %195 : int[] = prim::ListConstruct(%130, %130), scope: __module.model.2/__module.model.2.cv2/__module.model.2.cv2.conv\n\t\t    %input.31 : Tensor = aten::_convolution(%input.29, %weight.263, %132, %192, %193, %194, %129, %195, %131, %129, %128, %128, %128), scope: __module.model.2/__module.model.2.cv2/__module.model.2.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.125 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.11)\n\t\t    %running_mean.125 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.11)\n\t\t    %bias.137 : Tensor = prim::GetAttr[name=\"bias\"](%bn.11)\n\t\t    %weight.265 : Tensor = prim::GetAttr[name=\"weight\"](%bn.11)\n\t\t    %input.33 : Tensor = aten::batch_norm(%input.31, %weight.265, %bias.137, %running_mean.125, %running_var.125, %129, %134, %133, %128), scope: __module.model.2/__module.model.2.cv2/__module.model.2.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.35 : Tensor = aten::silu_(%input.33), scope: __module.model.2/__module.model.2.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %203 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.3/__module.model.3.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %204 : float = prim::Constant[value=0.001](), scope: __module.model.3/__module.model.3.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %205 : NoneType = prim::Constant(), scope: __module.model.3/__module.model.3.conv\n\t\t    %206 : int = prim::Constant[value=2](), scope: __module.model.3/__module.model.3.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %207 : int = prim::Constant[value=1](), scope: __module.model.3/__module.model.3.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %208 : bool = prim::Constant[value=0](), scope: __module.model.3/__module.model.3.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %209 : int = prim::Constant[value=0](), scope: __module.model.3/__module.model.3.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %210 : bool = prim::Constant[value=1](), scope: __module.model.3/__module.model.3.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %bn.13 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_3)\n\t\t    %conv.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_3)\n\t\t    %weight.267 : Tensor = prim::GetAttr[name=\"weight\"](%conv.13)\n\t\t    %214 : int[] = prim::ListConstruct(%206, %206), scope: __module.model.3/__module.model.3.conv\n\t\t    %215 : int[] = prim::ListConstruct(%207, %207), scope: __module.model.3/__module.model.3.conv\n\t\t    %216 : int[] = prim::ListConstruct(%207, %207), scope: __module.model.3/__module.model.3.conv\n\t\t    %217 : int[] = prim::ListConstruct(%209, %209), scope: __module.model.3/__module.model.3.conv\n\t\t    %input.37 : Tensor = aten::_convolution(%input.35, %weight.267, %205, %214, %215, %216, %208, %217, %207, %208, %210, %210, %210), scope: __module.model.3/__module.model.3.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.127 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.13)\n\t\t    %running_mean.127 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.13)\n\t\t    %bias.139 : Tensor = prim::GetAttr[name=\"bias\"](%bn.13)\n\t\t    %weight.269 : Tensor = prim::GetAttr[name=\"weight\"](%bn.13)\n\t\t    %input.39 : Tensor = aten::batch_norm(%input.37, %weight.269, %bias.139, %running_mean.127, %running_var.127, %208, %203, %204, %210), scope: __module.model.3/__module.model.3.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.41 : Tensor = aten::silu_(%input.39), scope: __module.model.3/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %225 : int = prim::Constant[value=2](), scope: __module.model.4 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %226 : bool = prim::Constant[value=1](), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %227 : bool = prim::Constant[value=0](), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %228 : int = prim::Constant[value=0](), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %229 : int = prim::Constant[value=1](), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %230 : NoneType = prim::Constant(), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv\n\t\t    %231 : float = prim::Constant[value=0.001](), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %232 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.9 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_4)\n\t\t    %m.5 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_4)\n\t\t    %_1.5 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"1\"](%m.5)\n\t\t    %m.3 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_4)\n\t\t    %_0.5 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m.3)\n\t\t    %cv1.5 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_4)\n\t\t    %bn.15 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.5)\n\t\t    %conv.15 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.5)\n\t\t    %weight.271 : Tensor = prim::GetAttr[name=\"weight\"](%conv.15)\n\t\t    %242 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv\n\t\t    %243 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv\n\t\t    %244 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv\n\t\t    %245 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv\n\t\t    %input.43 : Tensor = aten::_convolution(%input.41, %weight.271, %230, %242, %243, %244, %227, %245, %229, %227, %226, %226, %226), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.129 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.15)\n\t\t    %running_mean.129 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.15)\n\t\t    %bias.141 : Tensor = prim::GetAttr[name=\"bias\"](%bn.15)\n\t\t    %weight.273 : Tensor = prim::GetAttr[name=\"weight\"](%bn.15)\n\t\t    %input.45 : Tensor = aten::batch_norm(%input.43, %weight.273, %bias.141, %running_mean.129, %running_var.129, %227, %232, %231, %226), scope: __module.model.4/__module.model.4.cv1/__module.model.4.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %252 : Tensor = aten::silu_(%input.45), scope: __module.model.4/__module.model.4.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %253 : Tensor[] = aten::chunk(%252, %225, %229), scope: __module.model.4 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %254 : Tensor, %input.47 : Tensor = prim::ListUnpack(%253), scope: __module.model.4\n\t\t    %cv2.5 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.5)\n\t\t    %cv1.7 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.5)\n\t\t    %bn.17 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.7)\n\t\t    %conv.17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.7)\n\t\t    %weight.275 : Tensor = prim::GetAttr[name=\"weight\"](%conv.17)\n\t\t    %261 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv1/__module.model.4.m.0.cv1.conv\n\t\t    %262 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv1/__module.model.4.m.0.cv1.conv\n\t\t    %263 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv1/__module.model.4.m.0.cv1.conv\n\t\t    %264 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv1/__module.model.4.m.0.cv1.conv\n\t\t    %input.49 : Tensor = aten::_convolution(%input.47, %weight.275, %230, %261, %262, %263, %227, %264, %229, %227, %226, %226, %226), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv1/__module.model.4.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.131 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.17)\n\t\t    %running_mean.131 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.17)\n\t\t    %bias.143 : Tensor = prim::GetAttr[name=\"bias\"](%bn.17)\n\t\t    %weight.277 : Tensor = prim::GetAttr[name=\"weight\"](%bn.17)\n\t\t    %input.51 : Tensor = aten::batch_norm(%input.49, %weight.277, %bias.143, %running_mean.131, %running_var.131, %227, %232, %231, %226), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv1/__module.model.4.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.53 : Tensor = aten::silu_(%input.51), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.5)\n\t\t    %conv.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.5)\n\t\t    %weight.279 : Tensor = prim::GetAttr[name=\"weight\"](%conv.19)\n\t\t    %275 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv2/__module.model.4.m.0.cv2.conv\n\t\t    %276 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv2/__module.model.4.m.0.cv2.conv\n\t\t    %277 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv2/__module.model.4.m.0.cv2.conv\n\t\t    %278 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv2/__module.model.4.m.0.cv2.conv\n\t\t    %input.55 : Tensor = aten::_convolution(%input.53, %weight.279, %230, %275, %276, %277, %227, %278, %229, %227, %226, %226, %226), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv2/__module.model.4.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.133 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.19)\n\t\t    %running_mean.133 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.19)\n\t\t    %bias.145 : Tensor = prim::GetAttr[name=\"bias\"](%bn.19)\n\t\t    %weight.281 : Tensor = prim::GetAttr[name=\"weight\"](%bn.19)\n\t\t    %input.57 : Tensor = aten::batch_norm(%input.55, %weight.281, %bias.145, %running_mean.133, %running_var.133, %227, %232, %231, %226), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv2/__module.model.4.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %285 : Tensor = aten::silu_(%input.57), scope: __module.model.4/__module.model.4.m.0/__module.model.4.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %input.59 : Tensor = aten::add(%input.47, %285, %229), scope: __module.model.4/__module.model.4.m.0 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:347:0\n\t\t    %cv2.7 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_1.5)\n\t\t    %cv1.9 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_1.5)\n\t\t    %bn.21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.9)\n\t\t    %conv.21 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.9)\n\t\t    %weight.283 : Tensor = prim::GetAttr[name=\"weight\"](%conv.21)\n\t\t    %292 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv1/__module.model.4.m.1.cv1.conv\n\t\t    %293 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv1/__module.model.4.m.1.cv1.conv\n\t\t    %294 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv1/__module.model.4.m.1.cv1.conv\n\t\t    %295 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv1/__module.model.4.m.1.cv1.conv\n\t\t    %input.61 : Tensor = aten::_convolution(%input.59, %weight.283, %230, %292, %293, %294, %227, %295, %229, %227, %226, %226, %226), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv1/__module.model.4.m.1.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.135 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.21)\n\t\t    %running_mean.135 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.21)\n\t\t    %bias.147 : Tensor = prim::GetAttr[name=\"bias\"](%bn.21)\n\t\t    %weight.285 : Tensor = prim::GetAttr[name=\"weight\"](%bn.21)\n\t\t    %input.63 : Tensor = aten::batch_norm(%input.61, %weight.285, %bias.147, %running_mean.135, %running_var.135, %227, %232, %231, %226), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv1/__module.model.4.m.1.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.65 : Tensor = aten::silu_(%input.63), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.7)\n\t\t    %conv.23 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.7)\n\t\t    %weight.287 : Tensor = prim::GetAttr[name=\"weight\"](%conv.23)\n\t\t    %306 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv2/__module.model.4.m.1.cv2.conv\n\t\t    %307 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv2/__module.model.4.m.1.cv2.conv\n\t\t    %308 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv2/__module.model.4.m.1.cv2.conv\n\t\t    %309 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv2/__module.model.4.m.1.cv2.conv\n\t\t    %input.67 : Tensor = aten::_convolution(%input.65, %weight.287, %230, %306, %307, %308, %227, %309, %229, %227, %226, %226, %226), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv2/__module.model.4.m.1.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.137 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.23)\n\t\t    %running_mean.137 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.23)\n\t\t    %bias.149 : Tensor = prim::GetAttr[name=\"bias\"](%bn.23)\n\t\t    %weight.289 : Tensor = prim::GetAttr[name=\"weight\"](%bn.23)\n\t\t    %input.69 : Tensor = aten::batch_norm(%input.67, %weight.289, %bias.149, %running_mean.137, %running_var.137, %227, %232, %231, %226), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv2/__module.model.4.m.1.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %316 : Tensor = aten::silu_(%input.69), scope: __module.model.4/__module.model.4.m.1/__module.model.4.m.1.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %317 : Tensor = aten::add(%input.59, %316, %229), scope: __module.model.4/__module.model.4.m.1 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:347:0\n\t\t    %318 : Tensor[] = prim::ListConstruct(%254, %input.47, %input.59, %317), scope: __module.model.4\n\t\t    %input.71 : Tensor = aten::cat(%318, %229), scope: __module.model.4 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.9)\n\t\t    %conv.25 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.9)\n\t\t    %weight.291 : Tensor = prim::GetAttr[name=\"weight\"](%conv.25)\n\t\t    %323 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.cv2/__module.model.4.cv2.conv\n\t\t    %324 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.cv2/__module.model.4.cv2.conv\n\t\t    %325 : int[] = prim::ListConstruct(%229, %229), scope: __module.model.4/__module.model.4.cv2/__module.model.4.cv2.conv\n\t\t    %326 : int[] = prim::ListConstruct(%228, %228), scope: __module.model.4/__module.model.4.cv2/__module.model.4.cv2.conv\n\t\t    %input.73 : Tensor = aten::_convolution(%input.71, %weight.291, %230, %323, %324, %325, %227, %326, %229, %227, %226, %226, %226), scope: __module.model.4/__module.model.4.cv2/__module.model.4.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.139 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.25)\n\t\t    %running_mean.139 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.25)\n\t\t    %bias.151 : Tensor = prim::GetAttr[name=\"bias\"](%bn.25)\n\t\t    %weight.293 : Tensor = prim::GetAttr[name=\"weight\"](%bn.25)\n\t\t    %input.75 : Tensor = aten::batch_norm(%input.73, %weight.293, %bias.151, %running_mean.139, %running_var.139, %227, %232, %231, %226), scope: __module.model.4/__module.model.4.cv2/__module.model.4.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.77 : Tensor = aten::silu_(%input.75), scope: __module.model.4/__module.model.4.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %334 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.5/__module.model.5.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %335 : float = prim::Constant[value=0.001](), scope: __module.model.5/__module.model.5.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %336 : NoneType = prim::Constant(), scope: __module.model.5/__module.model.5.conv\n\t\t    %337 : int = prim::Constant[value=2](), scope: __module.model.5/__module.model.5.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %338 : int = prim::Constant[value=1](), scope: __module.model.5/__module.model.5.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %339 : bool = prim::Constant[value=0](), scope: __module.model.5/__module.model.5.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %340 : int = prim::Constant[value=0](), scope: __module.model.5/__module.model.5.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %341 : bool = prim::Constant[value=1](), scope: __module.model.5/__module.model.5.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %bn.27 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_5)\n\t\t    %conv.27 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_5)\n\t\t    %weight.295 : Tensor = prim::GetAttr[name=\"weight\"](%conv.27)\n\t\t    %345 : int[] = prim::ListConstruct(%337, %337), scope: __module.model.5/__module.model.5.conv\n\t\t    %346 : int[] = prim::ListConstruct(%338, %338), scope: __module.model.5/__module.model.5.conv\n\t\t    %347 : int[] = prim::ListConstruct(%338, %338), scope: __module.model.5/__module.model.5.conv\n\t\t    %348 : int[] = prim::ListConstruct(%340, %340), scope: __module.model.5/__module.model.5.conv\n\t\t    %input.79 : Tensor = aten::_convolution(%input.77, %weight.295, %336, %345, %346, %347, %339, %348, %338, %339, %341, %341, %341), scope: __module.model.5/__module.model.5.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.141 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.27)\n\t\t    %running_mean.141 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.27)\n\t\t    %bias.153 : Tensor = prim::GetAttr[name=\"bias\"](%bn.27)\n\t\t    %weight.297 : Tensor = prim::GetAttr[name=\"weight\"](%bn.27)\n\t\t    %input.81 : Tensor = aten::batch_norm(%input.79, %weight.297, %bias.153, %running_mean.141, %running_var.141, %339, %334, %335, %341), scope: __module.model.5/__module.model.5.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.83 : Tensor = aten::silu_(%input.81), scope: __module.model.5/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %356 : int = prim::Constant[value=2](), scope: __module.model.6 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %357 : bool = prim::Constant[value=1](), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %358 : bool = prim::Constant[value=0](), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %359 : int = prim::Constant[value=0](), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %360 : int = prim::Constant[value=1](), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %361 : NoneType = prim::Constant(), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv\n\t\t    %362 : float = prim::Constant[value=0.001](), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %363 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.15 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_6)\n\t\t    %m.9 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_6)\n\t\t    %_1.7 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"1\"](%m.9)\n\t\t    %m.7 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_6)\n\t\t    %_0.7 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m.7)\n\t\t    %cv1.11 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_6)\n\t\t    %bn.29 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.11)\n\t\t    %conv.29 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.11)\n\t\t    %weight.299 : Tensor = prim::GetAttr[name=\"weight\"](%conv.29)\n\t\t    %373 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv\n\t\t    %374 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv\n\t\t    %375 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv\n\t\t    %376 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv\n\t\t    %input.85 : Tensor = aten::_convolution(%input.83, %weight.299, %361, %373, %374, %375, %358, %376, %360, %358, %357, %357, %357), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.143 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.29)\n\t\t    %running_mean.143 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.29)\n\t\t    %bias.155 : Tensor = prim::GetAttr[name=\"bias\"](%bn.29)\n\t\t    %weight.301 : Tensor = prim::GetAttr[name=\"weight\"](%bn.29)\n\t\t    %input.87 : Tensor = aten::batch_norm(%input.85, %weight.301, %bias.155, %running_mean.143, %running_var.143, %358, %363, %362, %357), scope: __module.model.6/__module.model.6.cv1/__module.model.6.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %383 : Tensor = aten::silu_(%input.87), scope: __module.model.6/__module.model.6.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %384 : Tensor[] = aten::chunk(%383, %356, %360), scope: __module.model.6 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %385 : Tensor, %input.89 : Tensor = prim::ListUnpack(%384), scope: __module.model.6\n\t\t    %cv2.11 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.7)\n\t\t    %cv1.13 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.7)\n\t\t    %bn.31 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.13)\n\t\t    %conv.31 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.13)\n\t\t    %weight.303 : Tensor = prim::GetAttr[name=\"weight\"](%conv.31)\n\t\t    %392 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv1/__module.model.6.m.0.cv1.conv\n\t\t    %393 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv1/__module.model.6.m.0.cv1.conv\n\t\t    %394 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv1/__module.model.6.m.0.cv1.conv\n\t\t    %395 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv1/__module.model.6.m.0.cv1.conv\n\t\t    %input.91 : Tensor = aten::_convolution(%input.89, %weight.303, %361, %392, %393, %394, %358, %395, %360, %358, %357, %357, %357), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv1/__module.model.6.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.145 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.31)\n\t\t    %running_mean.145 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.31)\n\t\t    %bias.157 : Tensor = prim::GetAttr[name=\"bias\"](%bn.31)\n\t\t    %weight.305 : Tensor = prim::GetAttr[name=\"weight\"](%bn.31)\n\t\t    %input.93 : Tensor = aten::batch_norm(%input.91, %weight.305, %bias.157, %running_mean.145, %running_var.145, %358, %363, %362, %357), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv1/__module.model.6.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.95 : Tensor = aten::silu_(%input.93), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.33 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.11)\n\t\t    %conv.33 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.11)\n\t\t    %weight.307 : Tensor = prim::GetAttr[name=\"weight\"](%conv.33)\n\t\t    %406 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv2/__module.model.6.m.0.cv2.conv\n\t\t    %407 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv2/__module.model.6.m.0.cv2.conv\n\t\t    %408 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv2/__module.model.6.m.0.cv2.conv\n\t\t    %409 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv2/__module.model.6.m.0.cv2.conv\n\t\t    %input.97 : Tensor = aten::_convolution(%input.95, %weight.307, %361, %406, %407, %408, %358, %409, %360, %358, %357, %357, %357), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv2/__module.model.6.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.147 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.33)\n\t\t    %running_mean.147 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.33)\n\t\t    %bias.159 : Tensor = prim::GetAttr[name=\"bias\"](%bn.33)\n\t\t    %weight.309 : Tensor = prim::GetAttr[name=\"weight\"](%bn.33)\n\t\t    %input.99 : Tensor = aten::batch_norm(%input.97, %weight.309, %bias.159, %running_mean.147, %running_var.147, %358, %363, %362, %357), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv2/__module.model.6.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %416 : Tensor = aten::silu_(%input.99), scope: __module.model.6/__module.model.6.m.0/__module.model.6.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %input.101 : Tensor = aten::add(%input.89, %416, %360), scope: __module.model.6/__module.model.6.m.0 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:347:0\n\t\t    %cv2.13 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_1.7)\n\t\t    %cv1.15 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_1.7)\n\t\t    %bn.35 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.15)\n\t\t    %conv.35 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.15)\n\t\t    %weight.311 : Tensor = prim::GetAttr[name=\"weight\"](%conv.35)\n\t\t    %423 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv1/__module.model.6.m.1.cv1.conv\n\t\t    %424 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv1/__module.model.6.m.1.cv1.conv\n\t\t    %425 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv1/__module.model.6.m.1.cv1.conv\n\t\t    %426 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv1/__module.model.6.m.1.cv1.conv\n\t\t    %input.103 : Tensor = aten::_convolution(%input.101, %weight.311, %361, %423, %424, %425, %358, %426, %360, %358, %357, %357, %357), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv1/__module.model.6.m.1.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.149 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.35)\n\t\t    %running_mean.149 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.35)\n\t\t    %bias.161 : Tensor = prim::GetAttr[name=\"bias\"](%bn.35)\n\t\t    %weight.313 : Tensor = prim::GetAttr[name=\"weight\"](%bn.35)\n\t\t    %input.105 : Tensor = aten::batch_norm(%input.103, %weight.313, %bias.161, %running_mean.149, %running_var.149, %358, %363, %362, %357), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv1/__module.model.6.m.1.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.107 : Tensor = aten::silu_(%input.105), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.37 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.13)\n\t\t    %conv.37 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.13)\n\t\t    %weight.315 : Tensor = prim::GetAttr[name=\"weight\"](%conv.37)\n\t\t    %437 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv2/__module.model.6.m.1.cv2.conv\n\t\t    %438 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv2/__module.model.6.m.1.cv2.conv\n\t\t    %439 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv2/__module.model.6.m.1.cv2.conv\n\t\t    %440 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv2/__module.model.6.m.1.cv2.conv\n\t\t    %input.109 : Tensor = aten::_convolution(%input.107, %weight.315, %361, %437, %438, %439, %358, %440, %360, %358, %357, %357, %357), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv2/__module.model.6.m.1.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.151 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.37)\n\t\t    %running_mean.151 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.37)\n\t\t    %bias.163 : Tensor = prim::GetAttr[name=\"bias\"](%bn.37)\n\t\t    %weight.317 : Tensor = prim::GetAttr[name=\"weight\"](%bn.37)\n\t\t    %input.111 : Tensor = aten::batch_norm(%input.109, %weight.317, %bias.163, %running_mean.151, %running_var.151, %358, %363, %362, %357), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv2/__module.model.6.m.1.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %447 : Tensor = aten::silu_(%input.111), scope: __module.model.6/__module.model.6.m.1/__module.model.6.m.1.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %448 : Tensor = aten::add(%input.101, %447, %360), scope: __module.model.6/__module.model.6.m.1 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:347:0\n\t\t    %449 : Tensor[] = prim::ListConstruct(%385, %input.89, %input.101, %448), scope: __module.model.6\n\t\t    %input.113 : Tensor = aten::cat(%449, %360), scope: __module.model.6 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.39 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.15)\n\t\t    %conv.39 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.15)\n\t\t    %weight.319 : Tensor = prim::GetAttr[name=\"weight\"](%conv.39)\n\t\t    %454 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.cv2/__module.model.6.cv2.conv\n\t\t    %455 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.cv2/__module.model.6.cv2.conv\n\t\t    %456 : int[] = prim::ListConstruct(%360, %360), scope: __module.model.6/__module.model.6.cv2/__module.model.6.cv2.conv\n\t\t    %457 : int[] = prim::ListConstruct(%359, %359), scope: __module.model.6/__module.model.6.cv2/__module.model.6.cv2.conv\n\t\t    %input.115 : Tensor = aten::_convolution(%input.113, %weight.319, %361, %454, %455, %456, %358, %457, %360, %358, %357, %357, %357), scope: __module.model.6/__module.model.6.cv2/__module.model.6.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.153 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.39)\n\t\t    %running_mean.153 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.39)\n\t\t    %bias.165 : Tensor = prim::GetAttr[name=\"bias\"](%bn.39)\n\t\t    %weight.321 : Tensor = prim::GetAttr[name=\"weight\"](%bn.39)\n\t\t    %input.117 : Tensor = aten::batch_norm(%input.115, %weight.321, %bias.165, %running_mean.153, %running_var.153, %358, %363, %362, %357), scope: __module.model.6/__module.model.6.cv2/__module.model.6.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.119 : Tensor = aten::silu_(%input.117), scope: __module.model.6/__module.model.6.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %465 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.7/__module.model.7.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %466 : float = prim::Constant[value=0.001](), scope: __module.model.7/__module.model.7.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %467 : NoneType = prim::Constant(), scope: __module.model.7/__module.model.7.conv\n\t\t    %468 : int = prim::Constant[value=2](), scope: __module.model.7/__module.model.7.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %469 : int = prim::Constant[value=1](), scope: __module.model.7/__module.model.7.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %470 : bool = prim::Constant[value=0](), scope: __module.model.7/__module.model.7.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %471 : int = prim::Constant[value=0](), scope: __module.model.7/__module.model.7.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %472 : bool = prim::Constant[value=1](), scope: __module.model.7/__module.model.7.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %bn.41 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_7)\n\t\t    %conv.41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_7)\n\t\t    %weight.323 : Tensor = prim::GetAttr[name=\"weight\"](%conv.41)\n\t\t    %476 : int[] = prim::ListConstruct(%468, %468), scope: __module.model.7/__module.model.7.conv\n\t\t    %477 : int[] = prim::ListConstruct(%469, %469), scope: __module.model.7/__module.model.7.conv\n\t\t    %478 : int[] = prim::ListConstruct(%469, %469), scope: __module.model.7/__module.model.7.conv\n\t\t    %479 : int[] = prim::ListConstruct(%471, %471), scope: __module.model.7/__module.model.7.conv\n\t\t    %input.121 : Tensor = aten::_convolution(%input.119, %weight.323, %467, %476, %477, %478, %470, %479, %469, %470, %472, %472, %472), scope: __module.model.7/__module.model.7.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.155 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.41)\n\t\t    %running_mean.155 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.41)\n\t\t    %bias.167 : Tensor = prim::GetAttr[name=\"bias\"](%bn.41)\n\t\t    %weight.325 : Tensor = prim::GetAttr[name=\"weight\"](%bn.41)\n\t\t    %input.123 : Tensor = aten::batch_norm(%input.121, %weight.325, %bias.167, %running_mean.155, %running_var.155, %470, %465, %466, %472), scope: __module.model.7/__module.model.7.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.125 : Tensor = aten::silu_(%input.123), scope: __module.model.7/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %487 : int = prim::Constant[value=2](), scope: __module.model.8 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %488 : bool = prim::Constant[value=1](), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %489 : bool = prim::Constant[value=0](), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %490 : int = prim::Constant[value=0](), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %491 : int = prim::Constant[value=1](), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %492 : NoneType = prim::Constant(), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv\n\t\t    %493 : float = prim::Constant[value=0.001](), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %494 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.19 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_8)\n\t\t    %m.11 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_8)\n\t\t    %_0.9 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m.11)\n\t\t    %cv1.17 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_8)\n\t\t    %bn.43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.17)\n\t\t    %conv.43 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.17)\n\t\t    %weight.327 : Tensor = prim::GetAttr[name=\"weight\"](%conv.43)\n\t\t    %502 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv\n\t\t    %503 : int[] = prim::ListConstruct(%490, %490), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv\n\t\t    %504 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv\n\t\t    %505 : int[] = prim::ListConstruct(%490, %490), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv\n\t\t    %input.127 : Tensor = aten::_convolution(%input.125, %weight.327, %492, %502, %503, %504, %489, %505, %491, %489, %488, %488, %488), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.157 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.43)\n\t\t    %running_mean.157 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.43)\n\t\t    %bias.169 : Tensor = prim::GetAttr[name=\"bias\"](%bn.43)\n\t\t    %weight.329 : Tensor = prim::GetAttr[name=\"weight\"](%bn.43)\n\t\t    %input.129 : Tensor = aten::batch_norm(%input.127, %weight.329, %bias.169, %running_mean.157, %running_var.157, %489, %494, %493, %488), scope: __module.model.8/__module.model.8.cv1/__module.model.8.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %512 : Tensor = aten::silu_(%input.129), scope: __module.model.8/__module.model.8.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %513 : Tensor[] = aten::chunk(%512, %487, %491), scope: __module.model.8 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %514 : Tensor, %input.131 : Tensor = prim::ListUnpack(%513), scope: __module.model.8\n\t\t    %cv2.17 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.9)\n\t\t    %cv1.19 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.9)\n\t\t    %bn.45 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.19)\n\t\t    %conv.45 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.19)\n\t\t    %weight.331 : Tensor = prim::GetAttr[name=\"weight\"](%conv.45)\n\t\t    %521 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv1/__module.model.8.m.0.cv1.conv\n\t\t    %522 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv1/__module.model.8.m.0.cv1.conv\n\t\t    %523 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv1/__module.model.8.m.0.cv1.conv\n\t\t    %524 : int[] = prim::ListConstruct(%490, %490), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv1/__module.model.8.m.0.cv1.conv\n\t\t    %input.133 : Tensor = aten::_convolution(%input.131, %weight.331, %492, %521, %522, %523, %489, %524, %491, %489, %488, %488, %488), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv1/__module.model.8.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.159 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.45)\n\t\t    %running_mean.159 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.45)\n\t\t    %bias.171 : Tensor = prim::GetAttr[name=\"bias\"](%bn.45)\n\t\t    %weight.333 : Tensor = prim::GetAttr[name=\"weight\"](%bn.45)\n\t\t    %input.135 : Tensor = aten::batch_norm(%input.133, %weight.333, %bias.171, %running_mean.159, %running_var.159, %489, %494, %493, %488), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv1/__module.model.8.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.137 : Tensor = aten::silu_(%input.135), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.47 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.17)\n\t\t    %conv.47 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.17)\n\t\t    %weight.335 : Tensor = prim::GetAttr[name=\"weight\"](%conv.47)\n\t\t    %535 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv2/__module.model.8.m.0.cv2.conv\n\t\t    %536 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv2/__module.model.8.m.0.cv2.conv\n\t\t    %537 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv2/__module.model.8.m.0.cv2.conv\n\t\t    %538 : int[] = prim::ListConstruct(%490, %490), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv2/__module.model.8.m.0.cv2.conv\n\t\t    %input.139 : Tensor = aten::_convolution(%input.137, %weight.335, %492, %535, %536, %537, %489, %538, %491, %489, %488, %488, %488), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv2/__module.model.8.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.161 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.47)\n\t\t    %running_mean.161 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.47)\n\t\t    %bias.173 : Tensor = prim::GetAttr[name=\"bias\"](%bn.47)\n\t\t    %weight.337 : Tensor = prim::GetAttr[name=\"weight\"](%bn.47)\n\t\t    %input.141 : Tensor = aten::batch_norm(%input.139, %weight.337, %bias.173, %running_mean.161, %running_var.161, %489, %494, %493, %488), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv2/__module.model.8.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %545 : Tensor = aten::silu_(%input.141), scope: __module.model.8/__module.model.8.m.0/__module.model.8.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %546 : Tensor = aten::add(%input.131, %545, %491), scope: __module.model.8/__module.model.8.m.0 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:347:0\n\t\t    %547 : Tensor[] = prim::ListConstruct(%514, %input.131, %546), scope: __module.model.8\n\t\t    %input.143 : Tensor = aten::cat(%547, %491), scope: __module.model.8 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.49 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.19)\n\t\t    %conv.49 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.19)\n\t\t    %weight.339 : Tensor = prim::GetAttr[name=\"weight\"](%conv.49)\n\t\t    %552 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.cv2/__module.model.8.cv2.conv\n\t\t    %553 : int[] = prim::ListConstruct(%490, %490), scope: __module.model.8/__module.model.8.cv2/__module.model.8.cv2.conv\n\t\t    %554 : int[] = prim::ListConstruct(%491, %491), scope: __module.model.8/__module.model.8.cv2/__module.model.8.cv2.conv\n\t\t    %555 : int[] = prim::ListConstruct(%490, %490), scope: __module.model.8/__module.model.8.cv2/__module.model.8.cv2.conv\n\t\t    %input.145 : Tensor = aten::_convolution(%input.143, %weight.339, %492, %552, %553, %554, %489, %555, %491, %489, %488, %488, %488), scope: __module.model.8/__module.model.8.cv2/__module.model.8.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.163 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.49)\n\t\t    %running_mean.163 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.49)\n\t\t    %bias.175 : Tensor = prim::GetAttr[name=\"bias\"](%bn.49)\n\t\t    %weight.341 : Tensor = prim::GetAttr[name=\"weight\"](%bn.49)\n\t\t    %input.147 : Tensor = aten::batch_norm(%input.145, %weight.341, %bias.175, %running_mean.163, %running_var.163, %489, %494, %493, %488), scope: __module.model.8/__module.model.8.cv2/__module.model.8.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.149 : Tensor = aten::silu_(%input.147), scope: __module.model.8/__module.model.8.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %563 : int = prim::Constant[value=5](), scope: __module.model.9/__module.model.9.m # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:830:0\n\t\t    %564 : int = prim::Constant[value=2](), scope: __module.model.9/__module.model.9.m # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:830:0\n\t\t    %565 : bool = prim::Constant[value=1](), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %566 : bool = prim::Constant[value=0](), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %567 : int = prim::Constant[value=0](), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %568 : int = prim::Constant[value=1](), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %569 : NoneType = prim::Constant(), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv\n\t\t    %570 : float = prim::Constant[value=0.001](), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %571 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.21 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_9)\n\t\t    %m.13 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name=\"m\"](%_9)\n\t\t    %cv1.21 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_9)\n\t\t    %bn.51 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.21)\n\t\t    %conv.51 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.21)\n\t\t    %weight.343 : Tensor = prim::GetAttr[name=\"weight\"](%conv.51)\n\t\t    %578 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv\n\t\t    %579 : int[] = prim::ListConstruct(%567, %567), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv\n\t\t    %580 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv\n\t\t    %581 : int[] = prim::ListConstruct(%567, %567), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv\n\t\t    %input.151 : Tensor = aten::_convolution(%input.149, %weight.343, %569, %578, %579, %580, %566, %581, %568, %566, %565, %565, %565), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.165 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.51)\n\t\t    %running_mean.165 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.51)\n\t\t    %bias.177 : Tensor = prim::GetAttr[name=\"bias\"](%bn.51)\n\t\t    %weight.345 : Tensor = prim::GetAttr[name=\"weight\"](%bn.51)\n\t\t    %input.153 : Tensor = aten::batch_norm(%input.151, %weight.345, %bias.177, %running_mean.165, %running_var.165, %566, %571, %570, %565), scope: __module.model.9/__module.model.9.cv1/__module.model.9.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.155 : Tensor = aten::silu_(%input.153), scope: __module.model.9/__module.model.9.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %589 : int[] = prim::ListConstruct(%563, %563), scope: __module.model.9/__module.model.9.m\n\t\t    %590 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.m\n\t\t    %591 : int[] = prim::ListConstruct(%564, %564), scope: __module.model.9/__module.model.9.m\n\t\t    %592 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.m\n\t\t    %input.157 : Tensor = aten::max_pool2d(%input.155, %589, %590, %591, %592, %566), scope: __module.model.9/__module.model.9.m # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:830:0\n\t\t    %594 : int[] = prim::ListConstruct(%563, %563), scope: __module.model.9/__module.model.9.m\n\t\t    %595 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.m\n\t\t    %596 : int[] = prim::ListConstruct(%564, %564), scope: __module.model.9/__module.model.9.m\n\t\t    %597 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.m\n\t\t    %input.159 : Tensor = aten::max_pool2d(%input.157, %594, %595, %596, %597, %566), scope: __module.model.9/__module.model.9.m # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:830:0\n\t\t    %599 : int[] = prim::ListConstruct(%563, %563), scope: __module.model.9/__module.model.9.m\n\t\t    %600 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.m\n\t\t    %601 : int[] = prim::ListConstruct(%564, %564), scope: __module.model.9/__module.model.9.m\n\t\t    %602 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.m\n\t\t    %603 : Tensor = aten::max_pool2d(%input.159, %599, %600, %601, %602, %566), scope: __module.model.9/__module.model.9.m # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:830:0\n\t\t    %604 : Tensor[] = prim::ListConstruct(%input.155, %input.157, %input.159, %603), scope: __module.model.9\n\t\t    %input.161 : Tensor = aten::cat(%604, %568), scope: __module.model.9 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:188:0\n\t\t    %bn.53 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.21)\n\t\t    %conv.53 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.21)\n\t\t    %weight.347 : Tensor = prim::GetAttr[name=\"weight\"](%conv.53)\n\t\t    %609 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.cv2/__module.model.9.cv2.conv\n\t\t    %610 : int[] = prim::ListConstruct(%567, %567), scope: __module.model.9/__module.model.9.cv2/__module.model.9.cv2.conv\n\t\t    %611 : int[] = prim::ListConstruct(%568, %568), scope: __module.model.9/__module.model.9.cv2/__module.model.9.cv2.conv\n\t\t    %612 : int[] = prim::ListConstruct(%567, %567), scope: __module.model.9/__module.model.9.cv2/__module.model.9.cv2.conv\n\t\t    %input.163 : Tensor = aten::_convolution(%input.161, %weight.347, %569, %609, %610, %611, %566, %612, %568, %566, %565, %565, %565), scope: __module.model.9/__module.model.9.cv2/__module.model.9.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.167 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.53)\n\t\t    %running_mean.167 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.53)\n\t\t    %bias.179 : Tensor = prim::GetAttr[name=\"bias\"](%bn.53)\n\t\t    %weight.349 : Tensor = prim::GetAttr[name=\"weight\"](%bn.53)\n\t\t    %input.165 : Tensor = aten::batch_norm(%input.163, %weight.349, %bias.179, %running_mean.167, %running_var.167, %566, %571, %570, %565), scope: __module.model.9/__module.model.9.cv2/__module.model.9.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.167 : Tensor = aten::silu_(%input.165), scope: __module.model.9/__module.model.9.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %620 : float = prim::Constant[value=2.](), scope: __module.model.10 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4536:0\n\t\t    %621 : NoneType = prim::Constant(), scope: __module.model.10\n\t\t    %622 : float[] = prim::ListConstruct(%620, %620), scope: __module.model.10\n\t\t    %623 : Tensor = aten::upsample_nearest2d(%input.167, %621, %622), scope: __module.model.10 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4536:0\n\t\t    %624 : int = prim::Constant[value=1](), scope: __module.model.11 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %625 : Tensor[] = prim::ListConstruct(%623, %input.119), scope: __module.model.11\n\t\t    %input.169 : Tensor = aten::cat(%625, %624), scope: __module.model.11 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %627 : int = prim::Constant[value=2](), scope: __module.model.12 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %628 : bool = prim::Constant[value=1](), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %629 : bool = prim::Constant[value=0](), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %630 : int = prim::Constant[value=0](), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %631 : int = prim::Constant[value=1](), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %632 : NoneType = prim::Constant(), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv\n\t\t    %633 : float = prim::Constant[value=0.001](), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %634 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.25 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_12)\n\t\t    %m.15 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_12)\n\t\t    %_0.11 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m.15)\n\t\t    %cv1.23 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_12)\n\t\t    %bn.55 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.23)\n\t\t    %conv.55 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.23)\n\t\t    %weight.351 : Tensor = prim::GetAttr[name=\"weight\"](%conv.55)\n\t\t    %642 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv\n\t\t    %643 : int[] = prim::ListConstruct(%630, %630), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv\n\t\t    %644 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv\n\t\t    %645 : int[] = prim::ListConstruct(%630, %630), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv\n\t\t    %input.171 : Tensor = aten::_convolution(%input.169, %weight.351, %632, %642, %643, %644, %629, %645, %631, %629, %628, %628, %628), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.169 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.55)\n\t\t    %running_mean.169 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.55)\n\t\t    %bias.181 : Tensor = prim::GetAttr[name=\"bias\"](%bn.55)\n\t\t    %weight.353 : Tensor = prim::GetAttr[name=\"weight\"](%bn.55)\n\t\t    %input.173 : Tensor = aten::batch_norm(%input.171, %weight.353, %bias.181, %running_mean.169, %running_var.169, %629, %634, %633, %628), scope: __module.model.12/__module.model.12.cv1/__module.model.12.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %652 : Tensor = aten::silu_(%input.173), scope: __module.model.12/__module.model.12.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %653 : Tensor[] = aten::chunk(%652, %627, %631), scope: __module.model.12 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %654 : Tensor, %input.175 : Tensor = prim::ListUnpack(%653), scope: __module.model.12\n\t\t    %cv2.23 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.11)\n\t\t    %cv1.25 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.11)\n\t\t    %bn.57 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.25)\n\t\t    %conv.57 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.25)\n\t\t    %weight.355 : Tensor = prim::GetAttr[name=\"weight\"](%conv.57)\n\t\t    %661 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv1/__module.model.12.m.0.cv1.conv\n\t\t    %662 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv1/__module.model.12.m.0.cv1.conv\n\t\t    %663 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv1/__module.model.12.m.0.cv1.conv\n\t\t    %664 : int[] = prim::ListConstruct(%630, %630), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv1/__module.model.12.m.0.cv1.conv\n\t\t    %input.177 : Tensor = aten::_convolution(%input.175, %weight.355, %632, %661, %662, %663, %629, %664, %631, %629, %628, %628, %628), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv1/__module.model.12.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.171 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.57)\n\t\t    %running_mean.171 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.57)\n\t\t    %bias.183 : Tensor = prim::GetAttr[name=\"bias\"](%bn.57)\n\t\t    %weight.357 : Tensor = prim::GetAttr[name=\"weight\"](%bn.57)\n\t\t    %input.179 : Tensor = aten::batch_norm(%input.177, %weight.357, %bias.183, %running_mean.171, %running_var.171, %629, %634, %633, %628), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv1/__module.model.12.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.181 : Tensor = aten::silu_(%input.179), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.59 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.23)\n\t\t    %conv.59 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.23)\n\t\t    %weight.359 : Tensor = prim::GetAttr[name=\"weight\"](%conv.59)\n\t\t    %675 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv2/__module.model.12.m.0.cv2.conv\n\t\t    %676 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv2/__module.model.12.m.0.cv2.conv\n\t\t    %677 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv2/__module.model.12.m.0.cv2.conv\n\t\t    %678 : int[] = prim::ListConstruct(%630, %630), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv2/__module.model.12.m.0.cv2.conv\n\t\t    %input.183 : Tensor = aten::_convolution(%input.181, %weight.359, %632, %675, %676, %677, %629, %678, %631, %629, %628, %628, %628), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv2/__module.model.12.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.173 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.59)\n\t\t    %running_mean.173 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.59)\n\t\t    %bias.185 : Tensor = prim::GetAttr[name=\"bias\"](%bn.59)\n\t\t    %weight.361 : Tensor = prim::GetAttr[name=\"weight\"](%bn.59)\n\t\t    %input.185 : Tensor = aten::batch_norm(%input.183, %weight.361, %bias.185, %running_mean.173, %running_var.173, %629, %634, %633, %628), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv2/__module.model.12.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %685 : Tensor = aten::silu_(%input.185), scope: __module.model.12/__module.model.12.m.0/__module.model.12.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %686 : Tensor[] = prim::ListConstruct(%654, %input.175, %685), scope: __module.model.12\n\t\t    %input.187 : Tensor = aten::cat(%686, %631), scope: __module.model.12 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.61 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.25)\n\t\t    %conv.61 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.25)\n\t\t    %weight.363 : Tensor = prim::GetAttr[name=\"weight\"](%conv.61)\n\t\t    %691 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.cv2/__module.model.12.cv2.conv\n\t\t    %692 : int[] = prim::ListConstruct(%630, %630), scope: __module.model.12/__module.model.12.cv2/__module.model.12.cv2.conv\n\t\t    %693 : int[] = prim::ListConstruct(%631, %631), scope: __module.model.12/__module.model.12.cv2/__module.model.12.cv2.conv\n\t\t    %694 : int[] = prim::ListConstruct(%630, %630), scope: __module.model.12/__module.model.12.cv2/__module.model.12.cv2.conv\n\t\t    %input.189 : Tensor = aten::_convolution(%input.187, %weight.363, %632, %691, %692, %693, %629, %694, %631, %629, %628, %628, %628), scope: __module.model.12/__module.model.12.cv2/__module.model.12.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.175 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.61)\n\t\t    %running_mean.175 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.61)\n\t\t    %bias.187 : Tensor = prim::GetAttr[name=\"bias\"](%bn.61)\n\t\t    %weight.365 : Tensor = prim::GetAttr[name=\"weight\"](%bn.61)\n\t\t    %input.191 : Tensor = aten::batch_norm(%input.189, %weight.365, %bias.187, %running_mean.175, %running_var.175, %629, %634, %633, %628), scope: __module.model.12/__module.model.12.cv2/__module.model.12.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.193 : Tensor = aten::silu_(%input.191), scope: __module.model.12/__module.model.12.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %702 : float = prim::Constant[value=2.](), scope: __module.model.13 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4536:0\n\t\t    %703 : NoneType = prim::Constant(), scope: __module.model.13\n\t\t    %704 : float[] = prim::ListConstruct(%702, %702), scope: __module.model.13\n\t\t    %705 : Tensor = aten::upsample_nearest2d(%input.193, %703, %704), scope: __module.model.13 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4536:0\n\t\t    %706 : int = prim::Constant[value=1](), scope: __module.model.14 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %707 : Tensor[] = prim::ListConstruct(%705, %input.77), scope: __module.model.14\n\t\t    %input.195 : Tensor = aten::cat(%707, %706), scope: __module.model.14 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %709 : int = prim::Constant[value=2](), scope: __module.model.15 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %710 : bool = prim::Constant[value=1](), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %711 : bool = prim::Constant[value=0](), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %712 : int = prim::Constant[value=0](), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %713 : int = prim::Constant[value=1](), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %714 : NoneType = prim::Constant(), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv\n\t\t    %715 : float = prim::Constant[value=0.001](), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %716 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.29 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_15)\n\t\t    %m.17 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_15)\n\t\t    %_0.13 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m.17)\n\t\t    %cv1.27 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_15)\n\t\t    %bn.63 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.27)\n\t\t    %conv.63 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.27)\n\t\t    %weight.367 : Tensor = prim::GetAttr[name=\"weight\"](%conv.63)\n\t\t    %724 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv\n\t\t    %725 : int[] = prim::ListConstruct(%712, %712), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv\n\t\t    %726 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv\n\t\t    %727 : int[] = prim::ListConstruct(%712, %712), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv\n\t\t    %input.197 : Tensor = aten::_convolution(%input.195, %weight.367, %714, %724, %725, %726, %711, %727, %713, %711, %710, %710, %710), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.177 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.63)\n\t\t    %running_mean.177 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.63)\n\t\t    %bias.189 : Tensor = prim::GetAttr[name=\"bias\"](%bn.63)\n\t\t    %weight.369 : Tensor = prim::GetAttr[name=\"weight\"](%bn.63)\n\t\t    %input.199 : Tensor = aten::batch_norm(%input.197, %weight.369, %bias.189, %running_mean.177, %running_var.177, %711, %716, %715, %710), scope: __module.model.15/__module.model.15.cv1/__module.model.15.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %734 : Tensor = aten::silu_(%input.199), scope: __module.model.15/__module.model.15.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %735 : Tensor[] = aten::chunk(%734, %709, %713), scope: __module.model.15 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %736 : Tensor, %input.201 : Tensor = prim::ListUnpack(%735), scope: __module.model.15\n\t\t    %cv2.27 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.13)\n\t\t    %cv1.29 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.13)\n\t\t    %bn.65 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.29)\n\t\t    %conv.65 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.29)\n\t\t    %weight.371 : Tensor = prim::GetAttr[name=\"weight\"](%conv.65)\n\t\t    %743 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv1/__module.model.15.m.0.cv1.conv\n\t\t    %744 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv1/__module.model.15.m.0.cv1.conv\n\t\t    %745 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv1/__module.model.15.m.0.cv1.conv\n\t\t    %746 : int[] = prim::ListConstruct(%712, %712), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv1/__module.model.15.m.0.cv1.conv\n\t\t    %input.203 : Tensor = aten::_convolution(%input.201, %weight.371, %714, %743, %744, %745, %711, %746, %713, %711, %710, %710, %710), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv1/__module.model.15.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.179 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.65)\n\t\t    %running_mean.179 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.65)\n\t\t    %bias.191 : Tensor = prim::GetAttr[name=\"bias\"](%bn.65)\n\t\t    %weight.373 : Tensor = prim::GetAttr[name=\"weight\"](%bn.65)\n\t\t    %input.205 : Tensor = aten::batch_norm(%input.203, %weight.373, %bias.191, %running_mean.179, %running_var.179, %711, %716, %715, %710), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv1/__module.model.15.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.207 : Tensor = aten::silu_(%input.205), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.67 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.27)\n\t\t    %conv.67 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.27)\n\t\t    %weight.375 : Tensor = prim::GetAttr[name=\"weight\"](%conv.67)\n\t\t    %757 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv2/__module.model.15.m.0.cv2.conv\n\t\t    %758 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv2/__module.model.15.m.0.cv2.conv\n\t\t    %759 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv2/__module.model.15.m.0.cv2.conv\n\t\t    %760 : int[] = prim::ListConstruct(%712, %712), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv2/__module.model.15.m.0.cv2.conv\n\t\t    %input.209 : Tensor = aten::_convolution(%input.207, %weight.375, %714, %757, %758, %759, %711, %760, %713, %711, %710, %710, %710), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv2/__module.model.15.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.181 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.67)\n\t\t    %running_mean.181 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.67)\n\t\t    %bias.193 : Tensor = prim::GetAttr[name=\"bias\"](%bn.67)\n\t\t    %weight.377 : Tensor = prim::GetAttr[name=\"weight\"](%bn.67)\n\t\t    %input.211 : Tensor = aten::batch_norm(%input.209, %weight.377, %bias.193, %running_mean.181, %running_var.181, %711, %716, %715, %710), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv2/__module.model.15.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %767 : Tensor = aten::silu_(%input.211), scope: __module.model.15/__module.model.15.m.0/__module.model.15.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %768 : Tensor[] = prim::ListConstruct(%736, %input.201, %767), scope: __module.model.15\n\t\t    %input.213 : Tensor = aten::cat(%768, %713), scope: __module.model.15 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.69 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.29)\n\t\t    %conv.69 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.29)\n\t\t    %weight.379 : Tensor = prim::GetAttr[name=\"weight\"](%conv.69)\n\t\t    %773 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.cv2/__module.model.15.cv2.conv\n\t\t    %774 : int[] = prim::ListConstruct(%712, %712), scope: __module.model.15/__module.model.15.cv2/__module.model.15.cv2.conv\n\t\t    %775 : int[] = prim::ListConstruct(%713, %713), scope: __module.model.15/__module.model.15.cv2/__module.model.15.cv2.conv\n\t\t    %776 : int[] = prim::ListConstruct(%712, %712), scope: __module.model.15/__module.model.15.cv2/__module.model.15.cv2.conv\n\t\t    %input.215 : Tensor = aten::_convolution(%input.213, %weight.379, %714, %773, %774, %775, %711, %776, %713, %711, %710, %710, %710), scope: __module.model.15/__module.model.15.cv2/__module.model.15.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.183 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.69)\n\t\t    %running_mean.183 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.69)\n\t\t    %bias.195 : Tensor = prim::GetAttr[name=\"bias\"](%bn.69)\n\t\t    %weight.381 : Tensor = prim::GetAttr[name=\"weight\"](%bn.69)\n\t\t    %input.217 : Tensor = aten::batch_norm(%input.215, %weight.381, %bias.195, %running_mean.183, %running_var.183, %711, %716, %715, %710), scope: __module.model.15/__module.model.15.cv2/__module.model.15.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.219 : Tensor = aten::silu_(%input.217), scope: __module.model.15/__module.model.15.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %784 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.16/__module.model.16.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %785 : float = prim::Constant[value=0.001](), scope: __module.model.16/__module.model.16.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %786 : NoneType = prim::Constant(), scope: __module.model.16/__module.model.16.conv\n\t\t    %787 : int = prim::Constant[value=2](), scope: __module.model.16/__module.model.16.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %788 : int = prim::Constant[value=1](), scope: __module.model.16/__module.model.16.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %789 : bool = prim::Constant[value=0](), scope: __module.model.16/__module.model.16.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %790 : int = prim::Constant[value=0](), scope: __module.model.16/__module.model.16.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %791 : bool = prim::Constant[value=1](), scope: __module.model.16/__module.model.16.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %bn.71 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_16)\n\t\t    %conv.71 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_16)\n\t\t    %weight.383 : Tensor = prim::GetAttr[name=\"weight\"](%conv.71)\n\t\t    %795 : int[] = prim::ListConstruct(%787, %787), scope: __module.model.16/__module.model.16.conv\n\t\t    %796 : int[] = prim::ListConstruct(%788, %788), scope: __module.model.16/__module.model.16.conv\n\t\t    %797 : int[] = prim::ListConstruct(%788, %788), scope: __module.model.16/__module.model.16.conv\n\t\t    %798 : int[] = prim::ListConstruct(%790, %790), scope: __module.model.16/__module.model.16.conv\n\t\t    %input.221 : Tensor = aten::_convolution(%input.219, %weight.383, %786, %795, %796, %797, %789, %798, %788, %789, %791, %791, %791), scope: __module.model.16/__module.model.16.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.185 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.71)\n\t\t    %running_mean.185 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.71)\n\t\t    %bias.197 : Tensor = prim::GetAttr[name=\"bias\"](%bn.71)\n\t\t    %weight.385 : Tensor = prim::GetAttr[name=\"weight\"](%bn.71)\n\t\t    %input.223 : Tensor = aten::batch_norm(%input.221, %weight.385, %bias.197, %running_mean.185, %running_var.185, %789, %784, %785, %791), scope: __module.model.16/__module.model.16.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %805 : Tensor = aten::silu_(%input.223), scope: __module.model.16/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %806 : int = prim::Constant[value=1](), scope: __module.model.17 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %807 : Tensor[] = prim::ListConstruct(%805, %input.193), scope: __module.model.17\n\t\t    %input.225 : Tensor = aten::cat(%807, %806), scope: __module.model.17 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %809 : int = prim::Constant[value=2](), scope: __module.model.18 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %810 : bool = prim::Constant[value=1](), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %811 : bool = prim::Constant[value=0](), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %812 : int = prim::Constant[value=0](), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %813 : int = prim::Constant[value=1](), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %814 : NoneType = prim::Constant(), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv\n\t\t    %815 : float = prim::Constant[value=0.001](), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %816 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.33 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_18)\n\t\t    %m.19 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_18)\n\t\t    %_0.15 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m.19)\n\t\t    %cv1.31 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_18)\n\t\t    %bn.73 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.31)\n\t\t    %conv.73 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.31)\n\t\t    %weight.387 : Tensor = prim::GetAttr[name=\"weight\"](%conv.73)\n\t\t    %824 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv\n\t\t    %825 : int[] = prim::ListConstruct(%812, %812), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv\n\t\t    %826 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv\n\t\t    %827 : int[] = prim::ListConstruct(%812, %812), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv\n\t\t    %input.227 : Tensor = aten::_convolution(%input.225, %weight.387, %814, %824, %825, %826, %811, %827, %813, %811, %810, %810, %810), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.187 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.73)\n\t\t    %running_mean.187 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.73)\n\t\t    %bias.199 : Tensor = prim::GetAttr[name=\"bias\"](%bn.73)\n\t\t    %weight.389 : Tensor = prim::GetAttr[name=\"weight\"](%bn.73)\n\t\t    %input.229 : Tensor = aten::batch_norm(%input.227, %weight.389, %bias.199, %running_mean.187, %running_var.187, %811, %816, %815, %810), scope: __module.model.18/__module.model.18.cv1/__module.model.18.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %834 : Tensor = aten::silu_(%input.229), scope: __module.model.18/__module.model.18.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %835 : Tensor[] = aten::chunk(%834, %809, %813), scope: __module.model.18 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %836 : Tensor, %input.231 : Tensor = prim::ListUnpack(%835), scope: __module.model.18\n\t\t    %cv2.31 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.15)\n\t\t    %cv1.33 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.15)\n\t\t    %bn.75 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.33)\n\t\t    %conv.75 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.33)\n\t\t    %weight.391 : Tensor = prim::GetAttr[name=\"weight\"](%conv.75)\n\t\t    %843 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv1/__module.model.18.m.0.cv1.conv\n\t\t    %844 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv1/__module.model.18.m.0.cv1.conv\n\t\t    %845 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv1/__module.model.18.m.0.cv1.conv\n\t\t    %846 : int[] = prim::ListConstruct(%812, %812), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv1/__module.model.18.m.0.cv1.conv\n\t\t    %input.233 : Tensor = aten::_convolution(%input.231, %weight.391, %814, %843, %844, %845, %811, %846, %813, %811, %810, %810, %810), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv1/__module.model.18.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.189 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.75)\n\t\t    %running_mean.189 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.75)\n\t\t    %bias.201 : Tensor = prim::GetAttr[name=\"bias\"](%bn.75)\n\t\t    %weight.393 : Tensor = prim::GetAttr[name=\"weight\"](%bn.75)\n\t\t    %input.235 : Tensor = aten::batch_norm(%input.233, %weight.393, %bias.201, %running_mean.189, %running_var.189, %811, %816, %815, %810), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv1/__module.model.18.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.237 : Tensor = aten::silu_(%input.235), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.77 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.31)\n\t\t    %conv.77 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.31)\n\t\t    %weight.395 : Tensor = prim::GetAttr[name=\"weight\"](%conv.77)\n\t\t    %857 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv2/__module.model.18.m.0.cv2.conv\n\t\t    %858 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv2/__module.model.18.m.0.cv2.conv\n\t\t    %859 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv2/__module.model.18.m.0.cv2.conv\n\t\t    %860 : int[] = prim::ListConstruct(%812, %812), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv2/__module.model.18.m.0.cv2.conv\n\t\t    %input.239 : Tensor = aten::_convolution(%input.237, %weight.395, %814, %857, %858, %859, %811, %860, %813, %811, %810, %810, %810), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv2/__module.model.18.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.191 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.77)\n\t\t    %running_mean.191 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.77)\n\t\t    %bias.203 : Tensor = prim::GetAttr[name=\"bias\"](%bn.77)\n\t\t    %weight.397 : Tensor = prim::GetAttr[name=\"weight\"](%bn.77)\n\t\t    %input.241 : Tensor = aten::batch_norm(%input.239, %weight.397, %bias.203, %running_mean.191, %running_var.191, %811, %816, %815, %810), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv2/__module.model.18.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %867 : Tensor = aten::silu_(%input.241), scope: __module.model.18/__module.model.18.m.0/__module.model.18.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %868 : Tensor[] = prim::ListConstruct(%836, %input.231, %867), scope: __module.model.18\n\t\t    %input.243 : Tensor = aten::cat(%868, %813), scope: __module.model.18 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.79 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.33)\n\t\t    %conv.79 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.33)\n\t\t    %weight.399 : Tensor = prim::GetAttr[name=\"weight\"](%conv.79)\n\t\t    %873 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.cv2/__module.model.18.cv2.conv\n\t\t    %874 : int[] = prim::ListConstruct(%812, %812), scope: __module.model.18/__module.model.18.cv2/__module.model.18.cv2.conv\n\t\t    %875 : int[] = prim::ListConstruct(%813, %813), scope: __module.model.18/__module.model.18.cv2/__module.model.18.cv2.conv\n\t\t    %876 : int[] = prim::ListConstruct(%812, %812), scope: __module.model.18/__module.model.18.cv2/__module.model.18.cv2.conv\n\t\t    %input.245 : Tensor = aten::_convolution(%input.243, %weight.399, %814, %873, %874, %875, %811, %876, %813, %811, %810, %810, %810), scope: __module.model.18/__module.model.18.cv2/__module.model.18.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.193 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.79)\n\t\t    %running_mean.193 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.79)\n\t\t    %bias.205 : Tensor = prim::GetAttr[name=\"bias\"](%bn.79)\n\t\t    %weight.401 : Tensor = prim::GetAttr[name=\"weight\"](%bn.79)\n\t\t    %input.247 : Tensor = aten::batch_norm(%input.245, %weight.401, %bias.205, %running_mean.193, %running_var.193, %811, %816, %815, %810), scope: __module.model.18/__module.model.18.cv2/__module.model.18.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.249 : Tensor = aten::silu_(%input.247), scope: __module.model.18/__module.model.18.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %884 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.19/__module.model.19.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %885 : float = prim::Constant[value=0.001](), scope: __module.model.19/__module.model.19.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %886 : NoneType = prim::Constant(), scope: __module.model.19/__module.model.19.conv\n\t\t    %887 : int = prim::Constant[value=2](), scope: __module.model.19/__module.model.19.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %888 : int = prim::Constant[value=1](), scope: __module.model.19/__module.model.19.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %889 : bool = prim::Constant[value=0](), scope: __module.model.19/__module.model.19.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %890 : int = prim::Constant[value=0](), scope: __module.model.19/__module.model.19.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %891 : bool = prim::Constant[value=1](), scope: __module.model.19/__module.model.19.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %bn.81 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_19)\n\t\t    %conv.81 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_19)\n\t\t    %weight.403 : Tensor = prim::GetAttr[name=\"weight\"](%conv.81)\n\t\t    %895 : int[] = prim::ListConstruct(%887, %887), scope: __module.model.19/__module.model.19.conv\n\t\t    %896 : int[] = prim::ListConstruct(%888, %888), scope: __module.model.19/__module.model.19.conv\n\t\t    %897 : int[] = prim::ListConstruct(%888, %888), scope: __module.model.19/__module.model.19.conv\n\t\t    %898 : int[] = prim::ListConstruct(%890, %890), scope: __module.model.19/__module.model.19.conv\n\t\t    %input.251 : Tensor = aten::_convolution(%input.249, %weight.403, %886, %895, %896, %897, %889, %898, %888, %889, %891, %891, %891), scope: __module.model.19/__module.model.19.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.195 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.81)\n\t\t    %running_mean.195 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.81)\n\t\t    %bias.207 : Tensor = prim::GetAttr[name=\"bias\"](%bn.81)\n\t\t    %weight.405 : Tensor = prim::GetAttr[name=\"weight\"](%bn.81)\n\t\t    %input.253 : Tensor = aten::batch_norm(%input.251, %weight.405, %bias.207, %running_mean.195, %running_var.195, %889, %884, %885, %891), scope: __module.model.19/__module.model.19.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %905 : Tensor = aten::silu_(%input.253), scope: __module.model.19/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %906 : int = prim::Constant[value=1](), scope: __module.model.20 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %907 : Tensor[] = prim::ListConstruct(%905, %input.167), scope: __module.model.20\n\t\t    %input.255 : Tensor = aten::cat(%907, %906), scope: __module.model.20 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py:332:0\n\t\t    %909 : int = prim::Constant[value=2](), scope: __module.model.21 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %910 : bool = prim::Constant[value=1](), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %911 : bool = prim::Constant[value=0](), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %912 : int = prim::Constant[value=0](), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %913 : int = prim::Constant[value=1](), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %914 : NoneType = prim::Constant(), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv\n\t\t    %915 : float = prim::Constant[value=0.001](), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %916 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %cv2.37 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_21)\n\t\t    %m : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"m\"](%_21)\n\t\t    %_0.17 : __torch__.ultralytics.nn.modules.block.Bottleneck = prim::GetAttr[name=\"0\"](%m)\n\t\t    %cv1.35 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_21)\n\t\t    %bn.83 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1.35)\n\t\t    %conv.83 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1.35)\n\t\t    %weight.407 : Tensor = prim::GetAttr[name=\"weight\"](%conv.83)\n\t\t    %924 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv\n\t\t    %925 : int[] = prim::ListConstruct(%912, %912), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv\n\t\t    %926 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv\n\t\t    %927 : int[] = prim::ListConstruct(%912, %912), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv\n\t\t    %input.257 : Tensor = aten::_convolution(%input.255, %weight.407, %914, %924, %925, %926, %911, %927, %913, %911, %910, %910, %910), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.197 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.83)\n\t\t    %running_mean.197 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.83)\n\t\t    %bias.209 : Tensor = prim::GetAttr[name=\"bias\"](%bn.83)\n\t\t    %weight.409 : Tensor = prim::GetAttr[name=\"weight\"](%bn.83)\n\t\t    %input.259 : Tensor = aten::batch_norm(%input.257, %weight.409, %bias.209, %running_mean.197, %running_var.197, %911, %916, %915, %910), scope: __module.model.21/__module.model.21.cv1/__module.model.21.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %934 : Tensor = aten::silu_(%input.259), scope: __module.model.21/__module.model.21.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %935 : Tensor[] = aten::chunk(%934, %909, %913), scope: __module.model.21 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:237:0\n\t\t    %936 : Tensor, %input.261 : Tensor = prim::ListUnpack(%935), scope: __module.model.21\n\t\t    %cv2.35 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv2\"](%_0.17)\n\t\t    %cv1 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"cv1\"](%_0.17)\n\t\t    %bn.85 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv1)\n\t\t    %conv.85 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv1)\n\t\t    %weight.411 : Tensor = prim::GetAttr[name=\"weight\"](%conv.85)\n\t\t    %943 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv1/__module.model.21.m.0.cv1.conv\n\t\t    %944 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv1/__module.model.21.m.0.cv1.conv\n\t\t    %945 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv1/__module.model.21.m.0.cv1.conv\n\t\t    %946 : int[] = prim::ListConstruct(%912, %912), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv1/__module.model.21.m.0.cv1.conv\n\t\t    %input.263 : Tensor = aten::_convolution(%input.261, %weight.411, %914, %943, %944, %945, %911, %946, %913, %911, %910, %910, %910), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv1/__module.model.21.m.0.cv1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.199 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.85)\n\t\t    %running_mean.199 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.85)\n\t\t    %bias.211 : Tensor = prim::GetAttr[name=\"bias\"](%bn.85)\n\t\t    %weight.413 : Tensor = prim::GetAttr[name=\"weight\"](%bn.85)\n\t\t    %input.265 : Tensor = aten::batch_norm(%input.263, %weight.413, %bias.211, %running_mean.199, %running_var.199, %911, %916, %915, %910), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv1/__module.model.21.m.0.cv1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.267 : Tensor = aten::silu_(%input.265), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.87 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.35)\n\t\t    %conv.87 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.35)\n\t\t    %weight.415 : Tensor = prim::GetAttr[name=\"weight\"](%conv.87)\n\t\t    %957 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv2/__module.model.21.m.0.cv2.conv\n\t\t    %958 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv2/__module.model.21.m.0.cv2.conv\n\t\t    %959 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv2/__module.model.21.m.0.cv2.conv\n\t\t    %960 : int[] = prim::ListConstruct(%912, %912), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv2/__module.model.21.m.0.cv2.conv\n\t\t    %input.269 : Tensor = aten::_convolution(%input.267, %weight.415, %914, %957, %958, %959, %911, %960, %913, %911, %910, %910, %910), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv2/__module.model.21.m.0.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.201 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.87)\n\t\t    %running_mean.201 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.87)\n\t\t    %bias.213 : Tensor = prim::GetAttr[name=\"bias\"](%bn.87)\n\t\t    %weight.417 : Tensor = prim::GetAttr[name=\"weight\"](%bn.87)\n\t\t    %input.271 : Tensor = aten::batch_norm(%input.269, %weight.417, %bias.213, %running_mean.201, %running_var.201, %911, %916, %915, %910), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv2/__module.model.21.m.0.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %967 : Tensor = aten::silu_(%input.271), scope: __module.model.21/__module.model.21.m.0/__module.model.21.m.0.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %968 : Tensor[] = prim::ListConstruct(%936, %input.261, %967), scope: __module.model.21\n\t\t    %input.273 : Tensor = aten::cat(%968, %913), scope: __module.model.21 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:239:0\n\t\t    %bn.89 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%cv2.37)\n\t\t    %conv.89 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%cv2.37)\n\t\t    %weight.419 : Tensor = prim::GetAttr[name=\"weight\"](%conv.89)\n\t\t    %973 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.cv2/__module.model.21.cv2.conv\n\t\t    %974 : int[] = prim::ListConstruct(%912, %912), scope: __module.model.21/__module.model.21.cv2/__module.model.21.cv2.conv\n\t\t    %975 : int[] = prim::ListConstruct(%913, %913), scope: __module.model.21/__module.model.21.cv2/__module.model.21.cv2.conv\n\t\t    %976 : int[] = prim::ListConstruct(%912, %912), scope: __module.model.21/__module.model.21.cv2/__module.model.21.cv2.conv\n\t\t    %input.275 : Tensor = aten::_convolution(%input.273, %weight.419, %914, %973, %974, %975, %911, %976, %913, %911, %910, %910, %910), scope: __module.model.21/__module.model.21.cv2/__module.model.21.cv2.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.203 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.89)\n\t\t    %running_mean.203 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.89)\n\t\t    %bias.215 : Tensor = prim::GetAttr[name=\"bias\"](%bn.89)\n\t\t    %weight.421 : Tensor = prim::GetAttr[name=\"weight\"](%bn.89)\n\t\t    %input.277 : Tensor = aten::batch_norm(%input.275, %weight.421, %bias.215, %running_mean.203, %running_var.203, %911, %916, %915, %910), scope: __module.model.21/__module.model.21.cv2/__module.model.21.cv2.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.327 : Tensor = aten::silu_(%input.277), scope: __module.model.21/__module.model.21.cv2/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t+   %984 : Tensor = prim::Constant[value=<Tensor>](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:129:0\n\t\t-   %984 : Tensor = prim::Constant[value={2}](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:354:0\n\t\t?      ^\n\t\t+   %985 : Tensor = prim::Constant[value={2}](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:354:0\n\t\t?      ^\n\t\t+   %986 : Tensor = prim::Constant[value=<Tensor>](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:129:0\n\t\t-   %985 : int = prim::Constant[value=4](), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?      ^\n\t\t+   %987 : int = prim::Constant[value=4](), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?      ^\n\t\t-   %986 : int = prim::Constant[value=16](), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?      ^\n\t\t+   %988 : int = prim::Constant[value=16](), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?      ^\n\t\t-   %987 : int = prim::Constant[value=64](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:983:0\n\t\t?      ^\n\t\t+   %989 : int = prim::Constant[value=64](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:983:0\n\t\t?      ^\n\t\t-   %988 : str = prim::Constant[value=\"ij\"](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/functional.py:534:0\n\t\t-   %989 : Tensor = prim::Constant[value={0.5}](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %990 : Device = prim::Constant[value=\"cuda:0\"](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %991 : int = prim::Constant[value=6](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %992 : int = prim::Constant[value=3](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:339:0\n\t\t-   %993 : Tensor = prim::Constant[value=  8  16  32 [ CUDAFloatType{3} ]](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1119:0\n\t\t-   %994 : int = prim::Constant[value=2](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?      ^\n\t\t+   %990 : int = prim::Constant[value=2](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?      ^\n\t\t-   %995 : int = prim::Constant[value=-1](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?      ^\n\t\t+   %991 : int = prim::Constant[value=-1](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?      ^\n\t\t-   %996 : int = prim::Constant[value=65](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?      ^\n\t\t+   %992 : int = prim::Constant[value=65](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?      ^\n\t\t-   %997 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?      ^^^\n\t\t+   %993 : float = prim::Constant[value=0.029999999999999999](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?      ^^^\n\t\t-   %998 : float = prim::Constant[value=0.001](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?      ^^^\n\t\t+   %994 : float = prim::Constant[value=0.001](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?      ^^^\n\t\t-   %999 : NoneType = prim::Constant(), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?      ^\n\t\t+   %995 : NoneType = prim::Constant(), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?      ^\n\t\t-   %1000 : int = prim::Constant[value=1](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^^^^^^\n\t\t+   %996 : int = prim::Constant[value=1](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^^^^^\n\t\t-   %1001 : bool = prim::Constant[value=0](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^^\n\t\t+   %997 : bool = prim::Constant[value=0](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^\n\t\t-   %1002 : int = prim::Constant[value=0](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^^^^^^\n\t\t+   %998 : int = prim::Constant[value=0](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^^^^^\n\t\t-   %1003 : bool = prim::Constant[value=1](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^^\n\t\t+   %999 : bool = prim::Constant[value=1](), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?    ^^^^^\n\t\t    %dfl : __torch__.ultralytics.nn.modules.block.DFL = prim::GetAttr[name=\"dfl\"](%_22)\n\t\t    %cv3 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"cv3\"](%_22)\n\t\t    %_2 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"2\"](%cv3)\n\t\t    %cv2 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"cv2\"](%_22)\n\t\t    %_2.17 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"2\"](%cv2)\n\t\t    %cv3.7 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"cv3\"](%_22)\n\t\t    %_1.21 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"1\"](%cv3.7)\n\t\t    %cv2.41 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"cv2\"](%_22)\n\t\t    %_1.17 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"1\"](%cv2.41)\n\t\t    %cv3.5 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"cv3\"](%_22)\n\t\t    %_0.25 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%cv3.5)\n\t\t    %cv2.39 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"cv2\"](%_22)\n\t\t    %_0.21 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%cv2.39)\n\t\t    %_2.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%_0.21)\n\t\t    %_1.9 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%_0.21)\n\t\t    %_0.19 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"0\"](%_0.21)\n\t\t    %bn.91 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_0.19)\n\t\t    %conv.91 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_0.19)\n\t\t    %weight.423 : Tensor = prim::GetAttr[name=\"weight\"](%conv.91)\n\t\t+   %1019 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t-   %1023 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1020 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1024 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1021 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1025 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1022 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1026 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv\n\t\t-   %input.279 : Tensor = aten::_convolution(%input.219, %weight.423, %999, %1023, %1024, %1025, %1001, %1026, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ---------------------      ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.279 : Tensor = aten::_convolution(%input.219, %weight.423, %995, %1019, %1020, %1021, %997, %1022, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.205 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.91)\n\t\t    %running_mean.205 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.91)\n\t\t    %bias.217 : Tensor = prim::GetAttr[name=\"bias\"](%bn.91)\n\t\t    %weight.425 : Tensor = prim::GetAttr[name=\"weight\"](%bn.91)\n\t\t-   %input.281 : Tensor = aten::batch_norm(%input.279, %weight.425, %bias.217, %running_mean.205, %running_var.205, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                   -------         -------\n\t\t+   %input.281 : Tensor = aten::batch_norm(%input.279, %weight.425, %bias.217, %running_mean.205, %running_var.205, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv2.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                             ++++++++++++\n\t\t    %input.283 : Tensor = aten::silu_(%input.281), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.0/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.93 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_1.9)\n\t\t    %conv.93 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_1.9)\n\t\t    %weight.427 : Tensor = prim::GetAttr[name=\"weight\"](%conv.93)\n\t\t-   %1037 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1033 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1038 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1034 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1039 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1035 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1040 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1036 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %input.285 : Tensor = aten::_convolution(%input.283, %weight.427, %999, %1037, %1038, %1039, %1001, %1040, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.285 : Tensor = aten::_convolution(%input.283, %weight.427, %995, %1033, %1034, %1035, %997, %1036, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.207 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.93)\n\t\t    %running_mean.207 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.93)\n\t\t    %bias.219 : Tensor = prim::GetAttr[name=\"bias\"](%bn.93)\n\t\t    %weight.429 : Tensor = prim::GetAttr[name=\"weight\"](%bn.93)\n\t\t-   %input.287 : Tensor = aten::batch_norm(%input.285, %weight.429, %bias.219, %running_mean.207, %running_var.207, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.287 : Tensor = aten::batch_norm(%input.285, %weight.429, %bias.219, %running_mean.207, %running_var.207, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv2.0.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.289 : Tensor = aten::silu_(%input.287), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bias.221 : Tensor = prim::GetAttr[name=\"bias\"](%_2.5)\n\t\t    %weight.431 : Tensor = prim::GetAttr[name=\"weight\"](%_2.5)\n\t\t-   %1050 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1046 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1051 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1047 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1052 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1048 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1053 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1049 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1054 : Tensor = aten::_convolution(%input.289, %weight.431, %bias.221, %1050, %1051, %1052, %1001, %1053, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t+   %1050 : Tensor = aten::_convolution(%input.289, %weight.431, %bias.221, %1046, %1047, %1048, %997, %1049, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.0/__module.model.22.cv2.0.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %_2.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%_0.25)\n\t\t    %_1.13 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%_0.25)\n\t\t    %_0.23 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"0\"](%_0.25)\n\t\t    %bn.95 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_0.23)\n\t\t    %conv.95 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_0.23)\n\t\t    %weight.433 : Tensor = prim::GetAttr[name=\"weight\"](%conv.95)\n\t\t+   %1057 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t+   %1058 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t+   %1059 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t-   %1061 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1060 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1062 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t-   %1063 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t-   %1064 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv\n\t\t-   %input.291 : Tensor = aten::_convolution(%input.219, %weight.433, %999, %1061, %1062, %1063, %1001, %1064, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^     ^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.291 : Tensor = aten::_convolution(%input.219, %weight.433, %995, %1057, %1058, %1059, %997, %1060, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.209 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.95)\n\t\t    %running_mean.209 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.95)\n\t\t    %bias.223 : Tensor = prim::GetAttr[name=\"bias\"](%bn.95)\n\t\t    %weight.435 : Tensor = prim::GetAttr[name=\"weight\"](%bn.95)\n\t\t-   %input.293 : Tensor = aten::batch_norm(%input.291, %weight.435, %bias.223, %running_mean.209, %running_var.209, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                   -------         ^^^^^^^^\n\t\t+   %input.293 : Tensor = aten::batch_norm(%input.291, %weight.435, %bias.223, %running_mean.209, %running_var.209, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.0.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                            ^^^^^^^^^^^^^\n\t\t    %input.295 : Tensor = aten::silu_(%input.293), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.0/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.97 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_1.13)\n\t\t    %conv.97 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_1.13)\n\t\t    %weight.437 : Tensor = prim::GetAttr[name=\"weight\"](%conv.97)\n\t\t-   %1075 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1071 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1076 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1072 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1077 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1073 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1078 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1074 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %input.297 : Tensor = aten::_convolution(%input.295, %weight.437, %999, %1075, %1076, %1077, %1001, %1078, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        -------           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.297 : Tensor = aten::_convolution(%input.295, %weight.437, %995, %1071, %1072, %1073, %997, %1074, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                               +++++++++++++++++++++++++++++++++    ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.211 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.97)\n\t\t    %running_mean.211 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.97)\n\t\t    %bias.225 : Tensor = prim::GetAttr[name=\"bias\"](%bn.97)\n\t\t    %weight.439 : Tensor = prim::GetAttr[name=\"weight\"](%bn.97)\n\t\t-   %input.299 : Tensor = aten::batch_norm(%input.297, %weight.439, %bias.225, %running_mean.211, %running_var.211, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.299 : Tensor = aten::batch_norm(%input.297, %weight.439, %bias.225, %running_mean.211, %running_var.211, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.0.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.301 : Tensor = aten::silu_(%input.299), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bias.227 : Tensor = prim::GetAttr[name=\"bias\"](%_2.9)\n\t\t    %weight.441 : Tensor = prim::GetAttr[name=\"weight\"](%_2.9)\n\t\t-   %1088 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1084 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1089 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1085 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1090 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1086 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1091 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1087 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1092 : Tensor = aten::_convolution(%input.301, %weight.441, %bias.227, %1088, %1089, %1090, %1001, %1091, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %1088 : Tensor = aten::_convolution(%input.301, %weight.441, %bias.227, %1084, %1085, %1086, %997, %1087, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.0/__module.model.22.cv3.0.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1093 : Tensor[] = prim::ListConstruct(%1054, %1092), scope: __module.model.22\n\t\t?       -                                      ^     ^^\n\t\t+   %1089 : Tensor[] = prim::ListConstruct(%1050, %1088), scope: __module.model.22\n\t\t?      +                                       ^     ^^\n\t\t-   %xi.1 : Tensor = aten::cat(%1093, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:70:0\n\t\t?                                  -   ^^^^\n\t\t+   %xi.1 : Tensor = aten::cat(%1089, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:70:0\n\t\t?                                 +    ^^^\n\t\t    %_2.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%_1.17)\n\t\t    %_1.15 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%_1.17)\n\t\t    %_0.27 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"0\"](%_1.17)\n\t\t    %bn.99 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_0.27)\n\t\t    %conv.99 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_0.27)\n\t\t    %weight.443 : Tensor = prim::GetAttr[name=\"weight\"](%conv.99)\n\t\t+   %1097 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t+   %1098 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t+   %1099 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t-   %1101 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1100 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1102 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t-   %1103 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t-   %1104 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv\n\t\t-   %input.303 : Tensor = aten::_convolution(%input.249, %weight.443, %999, %1101, %1102, %1103, %1001, %1104, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.303 : Tensor = aten::_convolution(%input.249, %weight.443, %995, %1097, %1098, %1099, %997, %1100, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.213 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.99)\n\t\t    %running_mean.213 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.99)\n\t\t    %bias.229 : Tensor = prim::GetAttr[name=\"bias\"](%bn.99)\n\t\t    %weight.445 : Tensor = prim::GetAttr[name=\"weight\"](%bn.99)\n\t\t-   %input.305 : Tensor = aten::batch_norm(%input.303, %weight.445, %bias.229, %running_mean.213, %running_var.213, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.305 : Tensor = aten::batch_norm(%input.303, %weight.445, %bias.229, %running_mean.213, %running_var.213, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv2.1.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.307 : Tensor = aten::silu_(%input.305), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.0/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.101 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_1.15)\n\t\t    %conv.101 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_1.15)\n\t\t    %weight.447 : Tensor = prim::GetAttr[name=\"weight\"](%conv.101)\n\t\t-   %1115 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1111 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1116 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1112 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1117 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1113 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1118 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1114 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %input.309 : Tensor = aten::_convolution(%input.307, %weight.447, %999, %1115, %1116, %1117, %1001, %1118, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        -------           ^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.309 : Tensor = aten::_convolution(%input.307, %weight.447, %995, %1111, %1112, %1113, %997, %1114, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                               +++++++++++++++++++++++++++++++++    ^^    ^^^^^^^^^^^^^^^\n\t\t    %running_var.215 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.101)\n\t\t    %running_mean.215 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.101)\n\t\t    %bias.231 : Tensor = prim::GetAttr[name=\"bias\"](%bn.101)\n\t\t    %weight.449 : Tensor = prim::GetAttr[name=\"weight\"](%bn.101)\n\t\t-   %input.311 : Tensor = aten::batch_norm(%input.309, %weight.449, %bias.231, %running_mean.215, %running_var.215, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                   -------         ^^^^^^^^\n\t\t+   %input.311 : Tensor = aten::batch_norm(%input.309, %weight.449, %bias.231, %running_mean.215, %running_var.215, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv2.1.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                            ^^^^^^^^^^^^^\n\t\t    %input.313 : Tensor = aten::silu_(%input.311), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bias.233 : Tensor = prim::GetAttr[name=\"bias\"](%_2.11)\n\t\t    %weight.451 : Tensor = prim::GetAttr[name=\"weight\"](%_2.11)\n\t\t-   %1128 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1124 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1129 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1125 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1130 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1126 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1131 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1127 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1132 : Tensor = aten::_convolution(%input.313, %weight.451, %bias.233, %1128, %1129, %1130, %1001, %1131, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %1128 : Tensor = aten::_convolution(%input.313, %weight.451, %bias.233, %1124, %1125, %1126, %997, %1127, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.1/__module.model.22.cv2.1.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %_2.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%_1.21)\n\t\t    %_1.19 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%_1.21)\n\t\t    %_0.29 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"0\"](%_1.21)\n\t\t    %bn.103 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_0.29)\n\t\t    %conv.103 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_0.29)\n\t\t    %weight.453 : Tensor = prim::GetAttr[name=\"weight\"](%conv.103)\n\t\t-   %1139 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1135 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1140 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1136 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1141 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1137 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %1142 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1138 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %input.315 : Tensor = aten::_convolution(%input.249, %weight.453, %999, %1139, %1140, %1141, %1001, %1142, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t+   %input.315 : Tensor = aten::_convolution(%input.249, %weight.453, %995, %1135, %1136, %1137, %997, %1138, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.217 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.103)\n\t\t    %running_mean.217 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.103)\n\t\t    %bias.235 : Tensor = prim::GetAttr[name=\"bias\"](%bn.103)\n\t\t    %weight.455 : Tensor = prim::GetAttr[name=\"weight\"](%bn.103)\n\t\t-   %input.317 : Tensor = aten::batch_norm(%input.315, %weight.455, %bias.235, %running_mean.217, %running_var.217, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.317 : Tensor = aten::batch_norm(%input.315, %weight.455, %bias.235, %running_mean.217, %running_var.217, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.1.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.319 : Tensor = aten::silu_(%input.317), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.0/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.105 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_1.19)\n\t\t    %conv.105 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_1.19)\n\t\t    %weight.457 : Tensor = prim::GetAttr[name=\"weight\"](%conv.105)\n\t\t-   %1153 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t-   %1154 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t?      -                                 ^^^^   ^^^^\n\t\t+   %1149 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t?       +                                ^^^   ^^^\n\t\t-   %1155 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1150 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1156 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1151 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t+   %1152 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv\n\t\t-   %input.321 : Tensor = aten::_convolution(%input.319, %weight.457, %999, %1153, %1154, %1155, %1001, %1156, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^^^^^^^^ ^^^^^^^^^^^ ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.321 : Tensor = aten::_convolution(%input.319, %weight.457, %995, %1149, %1150, %1151, %997, %1152, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^ ^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.219 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.105)\n\t\t    %running_mean.219 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.105)\n\t\t    %bias.237 : Tensor = prim::GetAttr[name=\"bias\"](%bn.105)\n\t\t    %weight.459 : Tensor = prim::GetAttr[name=\"weight\"](%bn.105)\n\t\t-   %input.323 : Tensor = aten::batch_norm(%input.321, %weight.459, %bias.237, %running_mean.219, %running_var.219, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                   -------         ^^^^^^^^\n\t\t+   %input.323 : Tensor = aten::batch_norm(%input.321, %weight.459, %bias.237, %running_mean.219, %running_var.219, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.1.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t?                                                                                                                            ^^^^^^^^^^^^^\n\t\t    %input.325 : Tensor = aten::silu_(%input.323), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bias.239 : Tensor = prim::GetAttr[name=\"bias\"](%_2.13)\n\t\t    %weight.461 : Tensor = prim::GetAttr[name=\"weight\"](%_2.13)\n\t\t-   %1166 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1162 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1167 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1163 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1168 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1164 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1169 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1165 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1170 : Tensor = aten::_convolution(%input.325, %weight.461, %bias.239, %1166, %1167, %1168, %1001, %1169, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                     ^^^^^^^       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %1166 : Tensor = aten::_convolution(%input.325, %weight.461, %bias.239, %1162, %1163, %1164, %997, %1165, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.1/__module.model.22.cv3.1.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                     ^^^^^^^^^^^^^^^^^^^^       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1171 : Tensor[] = prim::ListConstruct(%1132, %1170), scope: __module.model.22\n\t\t?       -                                     -      ^^\n\t\t+   %1167 : Tensor[] = prim::ListConstruct(%1128, %1166), scope: __module.model.22\n\t\t?      +                                       +     ^^\n\t\t-   %xi.3 : Tensor = aten::cat(%1171, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:70:0\n\t\t?                                  -   ^^^^\n\t\t+   %xi.3 : Tensor = aten::cat(%1167, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:70:0\n\t\t?                                 +    ^^^\n\t\t    %_2.15 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%_2.17)\n\t\t    %_1.23 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%_2.17)\n\t\t    %_0.31 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"0\"](%_2.17)\n\t\t    %bn.107 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_0.31)\n\t\t    %conv.107 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_0.31)\n\t\t    %weight.463 : Tensor = prim::GetAttr[name=\"weight\"](%conv.107)\n\t\t-   %1179 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1175 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t+   %1176 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t+   %1177 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t-   %1180 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t?       -                                ^^^^   ^^^^\n\t\t+   %1178 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t?      +                                 ^^^   ^^^\n\t\t+   %input.329 : Tensor = aten::_convolution(%input.327, %weight.463, %995, %1175, %1176, %1177, %997, %1178, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t-   %1181 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t-   %1182 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv\n\t\t-   %input.329 : Tensor = aten::_convolution(%input.327, %weight.463, %999, %1179, %1180, %1181, %1001, %1182, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.221 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.107)\n\t\t    %running_mean.221 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.107)\n\t\t    %bias.241 : Tensor = prim::GetAttr[name=\"bias\"](%bn.107)\n\t\t    %weight.465 : Tensor = prim::GetAttr[name=\"weight\"](%bn.107)\n\t\t-   %input.331 : Tensor = aten::batch_norm(%input.329, %weight.465, %bias.241, %running_mean.221, %running_var.221, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.331 : Tensor = aten::batch_norm(%input.329, %weight.465, %bias.241, %running_mean.221, %running_var.221, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv2.2.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.333 : Tensor = aten::silu_(%input.331), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.0/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn.109 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_1.23)\n\t\t    %conv.109 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_1.23)\n\t\t    %weight.467 : Tensor = prim::GetAttr[name=\"weight\"](%conv.109)\n\t\t-   %1193 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?       -                                ^^^^   ^^^^\n\t\t+   %1189 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?      +                                 ^^^   ^^^\n\t\t-   %1194 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1190 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1195 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1191 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1196 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1192 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %input.335 : Tensor = aten::_convolution(%input.333, %weight.467, %999, %1193, %1194, %1195, %1001, %1196, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                       ---------------------       ^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.335 : Tensor = aten::_convolution(%input.333, %weight.467, %995, %1189, %1190, %1191, %997, %1192, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                             +++++++++ ^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.223 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.109)\n\t\t    %running_mean.223 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.109)\n\t\t    %bias.243 : Tensor = prim::GetAttr[name=\"bias\"](%bn.109)\n\t\t    %weight.469 : Tensor = prim::GetAttr[name=\"weight\"](%bn.109)\n\t\t-   %input.337 : Tensor = aten::batch_norm(%input.335, %weight.469, %bias.243, %running_mean.223, %running_var.223, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.337 : Tensor = aten::batch_norm(%input.335, %weight.469, %bias.243, %running_mean.223, %running_var.223, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv2.2.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.339 : Tensor = aten::silu_(%input.337), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bias.245 : Tensor = prim::GetAttr[name=\"bias\"](%_2.15)\n\t\t    %weight.471 : Tensor = prim::GetAttr[name=\"weight\"](%_2.15)\n\t\t-   %1206 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1202 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1207 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1203 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1208 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1204 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1209 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1205 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1210 : Tensor = aten::_convolution(%input.339, %weight.471, %bias.245, %1206, %1207, %1208, %1001, %1209, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                         ^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %1206 : Tensor = aten::_convolution(%input.339, %weight.471, %bias.245, %1202, %1203, %1204, %997, %1205, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv2.2/__module.model.22.cv2.2.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?      ^^^^                                                                     +++++++++++++++++++++++++++++++++    ^^    ^^^^^^^^^^^^^^^\n\t\t    %_2.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%_2)\n\t\t    %_1 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"1\"](%_2)\n\t\t    %_0 : __torch__.ultralytics.nn.modules.conv.Conv = prim::GetAttr[name=\"0\"](%_2)\n\t\t    %bn.111 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_0)\n\t\t    %conv.111 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_0)\n\t\t    %weight.473 : Tensor = prim::GetAttr[name=\"weight\"](%conv.111)\n\t\t-   %1217 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1213 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1218 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1214 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1219 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1215 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1220 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?      ^^                                ^^^^   ^^^^\n\t\t+   %1216 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv\n\t\t?      ^^                                ^^^   ^^^\n\t\t-   %input.341 : Tensor = aten::_convolution(%input.327, %weight.473, %999, %1217, %1218, %1219, %1001, %1220, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t+   %input.341 : Tensor = aten::_convolution(%input.327, %weight.473, %995, %1213, %1214, %1215, %997, %1216, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t    %running_var.225 : Tensor = prim::GetAttr[name=\"running_var\"](%bn.111)\n\t\t    %running_mean.225 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn.111)\n\t\t    %bias.247 : Tensor = prim::GetAttr[name=\"bias\"](%bn.111)\n\t\t    %weight.475 : Tensor = prim::GetAttr[name=\"weight\"](%bn.111)\n\t\t-   %input.343 : Tensor = aten::batch_norm(%input.341, %weight.475, %bias.247, %running_mean.225, %running_var.225, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.343 : Tensor = aten::batch_norm(%input.341, %weight.475, %bias.247, %running_mean.225, %running_var.225, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.0.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.345 : Tensor = aten::silu_(%input.343), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.0/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bn : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn\"](%_1)\n\t\t    %conv.113 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%_1)\n\t\t    %weight.477 : Tensor = prim::GetAttr[name=\"weight\"](%conv.113)\n\t\t-   %1231 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t-   %1232 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t?      -                                 ^^^^   ^^^^\n\t\t+   %1227 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t?       +                                ^^^   ^^^\n\t\t+   %1228 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t+   %1229 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t-   %1233 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1230 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1234 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv\n\t\t-   %input.347 : Tensor = aten::_convolution(%input.345, %weight.477, %999, %1231, %1232, %1233, %1001, %1234, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.347 : Tensor = aten::_convolution(%input.345, %weight.477, %995, %1227, %1228, %1229, %997, %1230, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var : Tensor = prim::GetAttr[name=\"running_var\"](%bn)\n\t\t    %running_mean : Tensor = prim::GetAttr[name=\"running_mean\"](%bn)\n\t\t    %bias.249 : Tensor = prim::GetAttr[name=\"bias\"](%bn)\n\t\t    %weight.479 : Tensor = prim::GetAttr[name=\"weight\"](%bn)\n\t\t-   %input.349 : Tensor = aten::batch_norm(%input.347, %weight.479, %bias.249, %running_mean, %running_var, %1001, %997, %998, %1003), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t+   %input.349 : Tensor = aten::batch_norm(%input.347, %weight.479, %bias.249, %running_mean, %running_var, %997, %993, %994, %999), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.bn # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2812:0\n\t\t    %input.351 : Tensor = aten::silu_(%input.349), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.1/__module.model.22.cv3.2.1.act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2379:0\n\t\t    %bias : Tensor = prim::GetAttr[name=\"bias\"](%_2.19)\n\t\t    %weight.481 : Tensor = prim::GetAttr[name=\"weight\"](%_2.19)\n\t\t-   %1244 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1240 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1245 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1241 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1246 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1242 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1247 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^^   ^^^^\n\t\t+   %1243 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2\n\t\t?       ^                                ^^^   ^^^\n\t\t-   %1248 : Tensor = aten::_convolution(%input.351, %weight.481, %bias, %1244, %1245, %1246, %1001, %1247, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?       ^^^                                                                 ^^^^^^^^^^^^^^    ^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %1244 : Tensor = aten::_convolution(%input.351, %weight.481, %bias, %1240, %1241, %1242, %997, %1243, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.cv3.2/__module.model.22.cv3.2.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?       ^^^                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^    ^^^^^^^^^^^^^^^\n\t\t-   %1249 : Tensor[] = prim::ListConstruct(%1210, %1248), scope: __module.model.22\n\t\t?       ^                                     -       ^\n\t\t+   %1245 : Tensor[] = prim::ListConstruct(%1206, %1244), scope: __module.model.22\n\t\t?       ^                                      +      ^\n\t\t-   %xi : Tensor = aten::cat(%1249, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:70:0\n\t\t?                                 ^^^^^^^\n\t\t+   %xi : Tensor = aten::cat(%1245, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:70:0\n\t\t?                                ++++ ^^\n\t\t-   %1251 : int = aten::size(%xi.1, %1002), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:103:0\n\t\t?      ^^                            ^^^^\n\t\t+   %1247 : int = aten::size(%xi.1, %998), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:103:0\n\t\t?      ^^                            ^^^\n\t\t+   %1248 : int[] = prim::ListConstruct(%1247, %992, %991), scope: __module.model.22\n\t\t+   %1249 : Tensor = aten::view(%xi.1, %1248), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t+   %1250 : int[] = prim::ListConstruct(%1247, %992, %991), scope: __module.model.22\n\t\t+   %1251 : Tensor = aten::view(%xi.3, %1250), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t-   %1252 : int[] = prim::ListConstruct(%1251, %996, %995), scope: __module.model.22\n\t\t?                                          ^^     ^     ^\n\t\t+   %1252 : int[] = prim::ListConstruct(%1247, %992, %991), scope: __module.model.22\n\t\t?                                          ^^     ^     ^\n\t\t-   %1253 : Tensor = aten::view(%xi.1, %1252), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?                                  --\n\t\t+   %1253 : Tensor = aten::view(%xi, %1252), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t-   %1254 : int[] = prim::ListConstruct(%1251, %996, %995), scope: __module.model.22\n\t\t-   %1255 : Tensor = aten::view(%xi.3, %1254), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t-   %1256 : int[] = prim::ListConstruct(%1251, %996, %995), scope: __module.model.22\n\t\t-   %1257 : Tensor = aten::view(%xi, %1256), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t-   %1258 : Tensor[] = prim::ListConstruct(%1253, %1255, %1257), scope: __module.model.22\n\t\t?       ^                                     ^^      ^      ^\n\t\t+   %1254 : Tensor[] = prim::ListConstruct(%1249, %1251, %1253), scope: __module.model.22\n\t\t?       ^                                     ^^      ^      ^\n\t\t-   %1259 : Tensor = aten::cat(%1258, %994), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?       ^                          ^     ^\n\t\t+   %1255 : Tensor = aten::cat(%1254, %990), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:104:0\n\t\t?       ^                          ^     ^\n\t\t-   %1260 : Tensor[] = aten::unbind(%993, %1002), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1119:0\n\t\t-   %stride.1 : Tensor, %stride.3 : Tensor, %stride : Tensor = prim::ListUnpack(%1260), scope: __module.model.22\n\t\t-   %1264 : Scalar = aten::ScalarImplicit(%stride), scope: __module.model.22\n\t\t-   %1265 : Scalar = aten::ScalarImplicit(%stride.3), scope: __module.model.22\n\t\t-   %1266 : Scalar = aten::ScalarImplicit(%stride.1), scope: __module.model.22\n\t\t-   %1267 : int = aten::size(%xi.1, %994), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:339:0\n\t\t-   %h.1 : Tensor = prim::NumToTensor(%1267), scope: __module.model.22\n\t\t-   %1269 : int = aten::size(%xi.1, %992), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:339:0\n\t\t-   %w.1 : Tensor = prim::NumToTensor(%1269), scope: __module.model.22\n\t\t-   %1271 : Tensor = aten::arange(%1269, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %1272 : Tensor = aten::add(%1271, %989, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %1273 : Tensor = aten::arange(%1267, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:341:0\n\t\t-   %1274 : Tensor = aten::add(%1273, %989, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:341:0\n\t\t-   %1275 : Tensor[] = prim::ListConstruct(%1274, %1272), scope: __module.model.22\n\t\t-   %1276 : Tensor[] = aten::meshgrid(%1275, %988), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/functional.py:534:0\n\t\t-   %sy.1 : Tensor, %sx.1 : Tensor = prim::ListUnpack(%1276), scope: __module.model.22\n\t\t-   %1279 : Tensor[] = prim::ListConstruct(%sx.1, %sy.1), scope: __module.model.22\n\t\t-   %1280 : Tensor = aten::stack(%1279, %995), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:343:0\n\t\t-   %1281 : int[] = prim::ListConstruct(%995, %994), scope: __module.model.22\n\t\t?      ^^                                  -     ^\n\t\t+   %1256 : int[] = prim::ListConstruct(%989, %996), scope: __module.model.22\n\t\t?      ^^                                 +      ^\n\t\t-   %1282 : Tensor = aten::view(%1280, %1281), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:343:0\n\t\t-   %1283 : Tensor = aten::mul(%h.1, %w.1), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:344:0\n\t\t-   %1284 : int = aten::Int(%1283), scope: __module.model.22\n\t\t-   %1285 : int[] = prim::ListConstruct(%1284, %1000), scope: __module.model.22\n\t\t-   %1286 : Tensor = aten::full(%1285, %1266, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:344:0\n\t\t-   %1287 : int = aten::size(%xi.3, %994), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:339:0\n\t\t-   %h.3 : Tensor = prim::NumToTensor(%1287), scope: __module.model.22\n\t\t-   %1289 : int = aten::size(%xi.3, %992), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:339:0\n\t\t-   %w.3 : Tensor = prim::NumToTensor(%1289), scope: __module.model.22\n\t\t-   %1291 : Tensor = aten::arange(%1289, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %1292 : Tensor = aten::add(%1291, %989, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %1293 : Tensor = aten::arange(%1287, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:341:0\n\t\t-   %1294 : Tensor = aten::add(%1293, %989, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:341:0\n\t\t-   %1295 : Tensor[] = prim::ListConstruct(%1294, %1292), scope: __module.model.22\n\t\t-   %1296 : Tensor[] = aten::meshgrid(%1295, %988), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/functional.py:534:0\n\t\t-   %sy.3 : Tensor, %sx.3 : Tensor = prim::ListUnpack(%1296), scope: __module.model.22\n\t\t-   %1299 : Tensor[] = prim::ListConstruct(%sx.3, %sy.3), scope: __module.model.22\n\t\t-   %1300 : Tensor = aten::stack(%1299, %995), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:343:0\n\t\t-   %1301 : int[] = prim::ListConstruct(%995, %994), scope: __module.model.22\n\t\t-   %1302 : Tensor = aten::view(%1300, %1301), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:343:0\n\t\t-   %1303 : Tensor = aten::mul(%h.3, %w.3), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:344:0\n\t\t-   %1304 : int = aten::Int(%1303), scope: __module.model.22\n\t\t-   %1305 : int[] = prim::ListConstruct(%1304, %1000), scope: __module.model.22\n\t\t-   %1306 : Tensor = aten::full(%1305, %1265, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:344:0\n\t\t-   %1307 : int = aten::size(%xi, %994), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:339:0\n\t\t-   %h : Tensor = prim::NumToTensor(%1307), scope: __module.model.22\n\t\t-   %1309 : int = aten::size(%xi, %992), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:339:0\n\t\t-   %w : Tensor = prim::NumToTensor(%1309), scope: __module.model.22\n\t\t-   %1311 : Tensor = aten::arange(%1309, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %1312 : Tensor = aten::add(%1311, %989, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:340:0\n\t\t-   %1313 : Tensor = aten::arange(%1307, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:341:0\n\t\t-   %1314 : Tensor = aten::add(%1313, %989, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:341:0\n\t\t-   %1315 : Tensor[] = prim::ListConstruct(%1314, %1312), scope: __module.model.22\n\t\t-   %1316 : Tensor[] = aten::meshgrid(%1315, %988), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/functional.py:534:0\n\t\t-   %sy : Tensor, %sx : Tensor = prim::ListUnpack(%1316), scope: __module.model.22\n\t\t-   %1319 : Tensor[] = prim::ListConstruct(%sx, %sy), scope: __module.model.22\n\t\t-   %1320 : Tensor = aten::stack(%1319, %995), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:343:0\n\t\t-   %1321 : int[] = prim::ListConstruct(%995, %994), scope: __module.model.22\n\t\t-   %1322 : Tensor = aten::view(%1320, %1321), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:343:0\n\t\t-   %1323 : Tensor = aten::mul(%h, %w), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:344:0\n\t\t-   %1324 : int = aten::Int(%1323), scope: __module.model.22\n\t\t-   %1325 : int[] = prim::ListConstruct(%1324, %1000), scope: __module.model.22\n\t\t-   %1326 : Tensor = aten::full(%1325, %1264, %991, %999, %990, %1001), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:344:0\n\t\t-   %1327 : Tensor[] = prim::ListConstruct(%1282, %1302, %1322), scope: __module.model.22\n\t\t-   %x.3 : Tensor = aten::cat(%1327, %1002), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:345:0\n\t\t-   %1329 : Tensor[] = prim::ListConstruct(%1286, %1306, %1326), scope: __module.model.22\n\t\t-   %x.5 : Tensor = aten::cat(%1329, %1002), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:345:0\n\t\t-   %1331 : Tensor = aten::transpose(%x.3, %1002, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:106:0\n\t\t-   %1332 : Tensor = aten::transpose(%x.5, %1002, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:106:0\n\t\t-   %1333 : int[] = prim::ListConstruct(%987, %1000), scope: __module.model.22\n\t\t-   %1334 : Tensor[] = aten::split_with_sizes(%1259, %1333, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:983:0\n\t\t?     ^^^                                         ^    ^^^   ^^^^\n\t\t+   %1257 : Tensor[] = aten::split_with_sizes(%1255, %1256, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:983:0\n\t\t?     ^^^                                         ^    ^^^   ^^^\n\t\t-   %x : Tensor, %cls : Tensor = prim::ListUnpack(%1334), scope: __module.model.22\n\t\t?                                                   ^^^\n\t\t+   %x : Tensor, %cls : Tensor = prim::ListUnpack(%1257), scope: __module.model.22\n\t\t?                                                   ^^^\n\t\t    %conv : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv\"](%dfl)\n\t\t-   %1338 : int = aten::size(%x, %1002), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:72:0\n\t\t-   %1339 : int = aten::size(%x, %994), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:72:0\n\t\t?     ^^^                           ^\n\t\t+   %1261 : int = aten::size(%x, %998), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:72:0\n\t\t?     ^^^                           ^\n\t\t+   %1262 : int = aten::size(%x, %990), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:72:0\n\t\t-   %1340 : int[] = prim::ListConstruct(%1338, %985, %986, %1339), scope: __module.model.22/__module.model.22.dfl\n\t\t?      --                                 ^^^     ^     ^    ^^^\n\t\t+   %1263 : int[] = prim::ListConstruct(%1261, %987, %988, %1262), scope: __module.model.22/__module.model.22.dfl\n\t\t?     ++                                  ^^^     ^     ^    ^^^\n\t\t-   %1341 : Tensor = aten::view(%x, %1340), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?     ^ -                              --\n\t\t+   %1264 : Tensor = aten::view(%x, %1263), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?     ^^                              ++\n\t\t-   %1342 : Tensor = aten::transpose(%1341, %994, %1000), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?     --                               ^ -     ^   ^^^^\n\t\t+   %1265 : Tensor = aten::transpose(%1264, %990, %996), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?      ++                              ^^      ^   ^^^\n\t\t-   %input : Tensor = aten::softmax(%1342, %1000, %999), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?                                     --  -------\n\t\t+   %input : Tensor = aten::softmax(%1265, %996, %995), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?                                      ++     ++++ ++\n\t\t    %weight : Tensor = prim::GetAttr[name=\"weight\"](%conv)\n\t\t-   %1345 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t-   %1346 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t?     ^^                                 ^^^^   ^^^^\n\t\t+   %1268 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t?     ^ +                                ^^^   ^^^\n\t\t+   %1269 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t-   %1347 : int[] = prim::ListConstruct(%1000, %1000), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t?     ^^                                 ^^^^   ^^^^\n\t\t+   %1270 : int[] = prim::ListConstruct(%996, %996), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t?     ^ +                                ^^^   ^^^\n\t\t-   %1348 : int[] = prim::ListConstruct(%1002, %1002), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t?     ^^^                                ^^^^   ^^^^\n\t\t+   %1271 : int[] = prim::ListConstruct(%998, %998), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv\n\t\t?     ^^^                                ^^^   ^^^\n\t\t-   %1349 : Tensor = aten::_convolution(%input, %weight, %999, %1345, %1346, %1347, %1001, %1348, %1000, %1001, %1003, %1003, %1003), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?     ^^^^^                                                 -------     ^^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %1272 : Tensor = aten::_convolution(%input, %weight, %995, %1268, %1269, %1270, %997, %1271, %996, %997, %999, %999, %999), scope: __module.model.22/__module.model.22.dfl/__module.model.22.dfl.conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:549:0\n\t\t?     ^^^^^                                                      ^ ^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1350 : int[] = prim::ListConstruct(%1338, %985, %1339), scope: __module.model.22/__module.model.22.dfl\n\t\t?      --                                 ^^^     ^    ^^^\n\t\t+   %1273 : int[] = prim::ListConstruct(%1261, %987, %1262), scope: __module.model.22/__module.model.22.dfl\n\t\t?     ++                                  ^^^     ^    ^^^\n\t\t-   %distance : Tensor = aten::view(%1349, %1350), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?                                     ^^^     --\n\t\t+   %distance : Tensor = aten::view(%1272, %1273), scope: __module.model.22/__module.model.22.dfl # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py:73:0\n\t\t?                                     ^^^    ++\n\t\t-   %anchor_points : Tensor = aten::unsqueeze(%1331, %1002), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:129:0\n\t\t?                                              ^^^^   ^^^^\n\t\t+   %anchor_points : Tensor = aten::unsqueeze(%986, %998), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:129:0\n\t\t?                                              ^^^   ^^^\n\t\t-   %1353 : Tensor[] = aten::chunk(%distance, %994, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:350:0\n\t\t?     ^^^                                        ^   ^^^^\n\t\t+   %1276 : Tensor[] = aten::chunk(%distance, %990, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:350:0\n\t\t?     ^^^                                        ^   ^^^\n\t\t-   %lt : Tensor, %rb : Tensor = prim::ListUnpack(%1353), scope: __module.model.22\n\t\t?                                                   ^^^\n\t\t+   %lt : Tensor, %rb : Tensor = prim::ListUnpack(%1276), scope: __module.model.22\n\t\t?                                                   ^^^\n\t\t-   %x1y1 : Tensor = aten::sub(%anchor_points, %lt, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:351:0\n\t\t?                                                    ^^^^\n\t\t+   %x1y1 : Tensor = aten::sub(%anchor_points, %lt, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:351:0\n\t\t?                                                    ^^^\n\t\t-   %x2y2 : Tensor = aten::add(%anchor_points, %rb, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:352:0\n\t\t?                                                    ^^^^\n\t\t+   %x2y2 : Tensor = aten::add(%anchor_points, %rb, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:352:0\n\t\t?                                                    ^^^\n\t\t-   %1358 : Tensor = aten::add(%x1y1, %x2y2, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:354:0\n\t\t?     ^^                                      ^^^^\n\t\t+   %1281 : Tensor = aten::add(%x1y1, %x2y2, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:354:0\n\t\t?     ^ +                                     ^^^\n\t\t-   %c_xy : Tensor = aten::div(%1358, %984), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:354:0\n\t\t?                                ^^      ^\n\t\t+   %c_xy : Tensor = aten::div(%1281, %985), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:354:0\n\t\t?                                ^ +     ^\n\t\t-   %wh : Tensor = aten::sub(%x2y2, %x1y1, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:355:0\n\t\t?                                           ^^^^\n\t\t+   %wh : Tensor = aten::sub(%x2y2, %x1y1, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:355:0\n\t\t?                                           ^^^\n\t\t-   %1361 : Tensor[] = prim::ListConstruct(%c_xy, %wh), scope: __module.model.22\n\t\t?     ^^^\n\t\t+   %1284 : Tensor[] = prim::ListConstruct(%c_xy, %wh), scope: __module.model.22\n\t\t?     ^^^\n\t\t-   %1362 : Tensor = aten::cat(%1361, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:356:0\n\t\t?     --                         ^ --------\n\t\t+   %1285 : Tensor = aten::cat(%1284, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:356:0\n\t\t?      ++                        ^^^^^^^^\n\t\t-   %dbox : Tensor = aten::mul(%1362, %1332), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:129:0\n\t\t?                                --    ^^^^\n\t\t+   %dbox : Tensor = aten::mul(%1285, %984), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:129:0\n\t\t?                                 ++   ^^^\n\t\t-   %1364 : Tensor = aten::sigmoid(%cls), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:131:0\n\t\t?     ^^^\n\t\t+   %1287 : Tensor = aten::sigmoid(%cls), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:131:0\n\t\t?     ^^^\n\t\t-   %1365 : Tensor[] = prim::ListConstruct(%dbox, %1364), scope: __module.model.22\n\t\t?     ^^^                                           ^^^\n\t\t+   %1288 : Tensor[] = prim::ListConstruct(%dbox, %1287), scope: __module.model.22\n\t\t?     ^^^                                           ^^^\n\t\t-   %1366 : Tensor = aten::cat(%1365, %1000), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:131:0\n\t\t?     ^^^                        ^ --------\n\t\t+   %1289 : Tensor = aten::cat(%1288, %996), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:131:0\n\t\t?     ^^^                        ^^^^^^^^\n\t\t-   %1367 : (Tensor, Tensor, Tensor, Tensor) = prim::TupleConstruct(%xi.1, %xi.3, %xi, %1366)\n\t\t?     ^^^                                                                                ^^^\n\t\t+   %1290 : (Tensor, Tensor, Tensor, Tensor) = prim::TupleConstruct(%xi.1, %xi.3, %xi, %1289)\n\t\t?     ^^^                                                                                ^^^\n\t\t-   %77 : Tensor, %78 : Tensor, %79 : Tensor, %80 : Tensor = prim::TupleUnpack(%1367)\n\t\t?                                                                                ^^^\n\t\t+   %77 : Tensor, %78 : Tensor, %79 : Tensor, %80 : Tensor = prim::TupleUnpack(%1290)\n\t\t?                                                                                ^^^\n\t\t    %81 : Tensor[] = prim::ListConstruct(%77, %78, %79)\n\t\t    %82 : (Tensor, Tensor[]) = prim::TupleConstruct(%80, %81)\n\t\t    return (%82)\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %model : __torch__.torch.nn.modules.container.___torch_mangle_5314.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t?                                                                ^^^\n\t\t+ %model : __torch__.torch.nn.modules.container.___torch_mangle_5595.Sequential = prim::GetAttr[name=\"model\"](%self.1)\n\t\t?                                                                ^^^\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\n\tNode:\n\t\t%984 : Tensor = prim::Constant[value={2}](), scope: __module.model.22 # /usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py:354:0\n\tSource Location:\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py(354): dist2bbox\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py(148): decode_bboxes\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py(129): _inference\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py(73): forward\n\t\t/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py(1726): _slow_forward\n\t\t/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py(1747): _call_impl\n\t\t/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py(151): _predict_once\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py(130): predict\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py(112): forward\n\t\t/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py(1726): _slow_forward\n\t\t/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py(1747): _call_impl\n\t\t/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl\n\t\t/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py(1278): trace_module\n\t\t/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py(698): _trace_impl\n\t\t/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py(1002): trace\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/utils/callbacks/tensorboard.py(49): _log_tensorboard_graph\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/utils/callbacks/tensorboard.py(84): on_train_start\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py(168): run_callbacks\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py(330): _do_train\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py(207): train\n\t\t/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py(802): train\n\t\t<ipython-input-16-bd73c31d0a9c>(53): <cell line: 4>\n\t\t/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py(3553): run_code\n\t\t/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py(3473): run_ast_nodes\n\t\t/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py(3257): run_cell_async\n\t\t/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py(78): _pseudo_sync_runner\n\t\t/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py(3030): _run_cell\n\t\t/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py(2975): run_cell\n\t\t/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py(539): run_cell\n\t\t/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py(302): do_execute\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/gen.py(234): wrapper\n\t\t/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py(539): execute_request\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/gen.py(234): wrapper\n\t\t/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py(261): dispatch_shell\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/gen.py(234): wrapper\n\t\t/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py(361): process_one\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/gen.py(786): run\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/gen.py(825): inner\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py(738): _run_callback\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py(685): <lambda>\n\t\t/usr/lib/python3.10/asyncio/events.py(80): _run\n\t\t/usr/lib/python3.10/asyncio/base_events.py(1909): _run_once\n\t\t/usr/lib/python3.10/asyncio/base_events.py(603): run_forever\n\t\t/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py(195): start\n\t\t/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py(619): start\n\t\t/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py(992): launch_instance\n\t\t/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py(37): <module>\n\t\t/usr/lib/python3.10/runpy.py(86): _run_code\n\t\t/usr/lib/python3.10/runpy.py(196): _run_module_as_main\n\tComparison exception: \tThe values for attribute 'shape' do not match: torch.Size([]) != torch.Size([1, 21504]).\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bd73c31d0a9c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ–∫—É—â–µ–º fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_config_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_time_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_time_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_train_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         LOGGER.info(\n\u001b[1;32m    332\u001b[0m             \u001b[0;34mf'Image sizes {self.args.imgsz} train, {self.args.imgsz} val\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mrun_callbacks\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;34m\"\"\"Run all existing callbacks associated with a particular event.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/callbacks/tensorboard.py\u001b[0m in \u001b[0;36mon_train_start\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;34m\"\"\"Log TensorBoard graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mWRITER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0m_log_tensorboard_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/callbacks/tensorboard.py\u001b[0m in \u001b[0;36m_log_tensorboard_graph\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"export\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Detect, RTDETRDecoder (Segment and Pose use Detect base class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mfuse\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_convs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuse_conv_and_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bn\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# remove batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_fuse\u001b[0m  \u001b[0;31m# update forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py\u001b[0m in \u001b[0;36mfuse_conv_and_bn\u001b[0;34m(conv, bn)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# Prepare filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mw_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mw_bn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0mfusedconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_bn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfusedconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just training"
      ],
      "metadata": {
        "id": "u9k5kZx1VOh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n.pt\")"
      ],
      "metadata": {
        "id": "-0L2dCJNVj_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data=\"conf_collab_aug.yaml\", epochs=100, imgsz=1024)\n",
        "\n",
        "metrics = model.val()\n",
        "\n",
        "print(metrics.box.map)\n",
        "print(metrics.box.map50)\n",
        "print(metrics.box.map75)\n",
        "print(metrics.box.maps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UTBjM7iCVfxJ",
        "outputId": "de64e24b-9a1e-4803-dc96-c14c51cfb4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=conf_collab_aug.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/YOLO_sech_1/train/labels.cache... 64 images, 10 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64/64 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLO_sech_1/val/labels.cache... 16 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      5.47G      2.749      9.621      2.397         26       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15   0.000208     0.0667   0.000111   3.34e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      5.17G      2.654      8.448      2.438         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15   0.000208     0.0667   0.000111   3.34e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      5.17G      2.529      7.801       2.25         28       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15   0.000417      0.133   0.000472   9.45e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      5.17G      2.005      6.226      1.932         17       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00187        0.6      0.015     0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      5.17G      1.959      5.603      1.846         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00167      0.533    0.00732     0.0037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      5.17G      1.858      5.311      1.764         28       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00187        0.6     0.0271    0.00672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      5.17G      1.682      5.376      1.603         26       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00104      0.333     0.0284    0.00647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      5.17G      1.746      5.334      1.656         28       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00146      0.467     0.0758     0.0108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      5.17G      1.699      4.688      1.602         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00125        0.4    0.00217   0.000702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      5.17G      1.878      5.315      1.761         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00167      0.533    0.00882    0.00203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      5.17G      1.665      4.746      1.584         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00187        0.6    0.00667    0.00317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      5.17G      1.495       4.48      1.506         32       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.72     0.0667     0.0726      0.054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      5.17G      1.724      4.365      1.661         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00208      0.667    0.00324   0.000756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      5.17G      1.676      4.112      1.587         30       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00229      0.733    0.00583    0.00128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      5.17G      1.583      4.323      1.505         17       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00125        0.4    0.00723    0.00249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      5.17G      1.433      3.592      1.386         35       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15     0.0449      0.133     0.0179    0.00325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      5.17G      1.479      4.151      1.476         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.169     0.0667     0.0216    0.00832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      5.17G      1.473      3.814      1.512         19       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15     0.0164      0.133    0.00744    0.00373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      5.17G      1.533      3.333      1.546         33       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15    0.00942      0.267    0.00706    0.00233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      5.17G      1.477        4.1      1.455         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.211      0.109     0.0367    0.00978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      5.17G      1.459      3.779      1.422         20       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.174      0.133      0.108     0.0564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      5.17G       1.58      3.569      1.402         22       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.295        0.2      0.121     0.0624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      5.17G      1.506      3.777      1.405         29       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.32     0.0667     0.0527     0.0302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      5.17G      1.435      3.862      1.422         20       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.143        0.2     0.0735     0.0455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      5.17G      1.393      3.554      1.367         26       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.166      0.133      0.117      0.069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      5.17G      1.424      3.459      1.448         20       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.066      0.333      0.071     0.0393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      5.17G      1.502      3.348      1.479         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.733      0.133      0.175      0.102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      5.17G      1.474      3.103      1.397         33       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.64        0.2      0.225       0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      5.17G      1.455       3.06      1.414         33       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.523      0.333      0.323      0.146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      5.17G      1.449      3.297      1.507         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.287      0.467      0.302      0.136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      5.17G      1.431      2.976      1.413         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.413      0.467      0.327      0.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      5.17G      1.393      3.176      1.372         26       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.496        0.4      0.328      0.164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      5.17G      1.359      2.804      1.373         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.626      0.267      0.325      0.153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      5.17G      1.292      2.582      1.282         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15        0.5      0.333      0.372      0.175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      5.17G      1.276      2.441      1.307         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.261      0.533      0.325      0.148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      5.17G      1.347      2.419      1.328         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.659        0.4      0.361      0.149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      5.17G      1.393      2.583      1.357         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.34        0.4      0.301      0.157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100      5.17G      1.341      2.776      1.327         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.378      0.267      0.319       0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      5.17G      1.363      2.845      1.334         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.272      0.267      0.217     0.0912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      5.17G      1.207       2.56      1.266         22       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.66        0.2      0.307      0.131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      5.17G      1.248      2.411      1.271         29       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.378      0.333      0.292      0.146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      5.17G      1.242      2.207      1.293         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.872        0.2      0.296       0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      5.17G      1.143      2.248      1.175         15       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.485      0.333      0.356      0.165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100      5.17G      1.142      1.969      1.203         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.917      0.333      0.395      0.211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      5.17G      1.116      1.982      1.177         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.933      0.333      0.387       0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      5.17G      1.171      2.005       1.22         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.572      0.333      0.315      0.162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      5.17G       1.22      2.157       1.29         26       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.239        0.4      0.267      0.135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      5.17G      1.099      2.039      1.186         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.381      0.267      0.239      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      5.17G      1.197      2.023      1.196         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.299      0.467      0.223      0.113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      5.17G      1.184      2.009      1.256         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.405      0.467      0.322      0.181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      5.17G      1.305       2.27      1.371         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.648      0.333      0.376      0.197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      5.17G      1.184      2.024      1.272         28       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.865      0.333      0.414      0.239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100      5.17G      1.122      1.793      1.212         28       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.689      0.333      0.399      0.223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      5.17G      1.041      1.829      1.135         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.632        0.4      0.377      0.201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100      5.17G       1.06      1.787      1.141         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.74        0.4      0.418      0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      5.17G      1.005      1.701      1.146         20       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.558        0.4      0.413      0.246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      5.17G      1.069      1.713       1.14         20       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.533        0.4        0.4      0.231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      5.17G      1.077      1.776      1.142         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.679        0.4      0.407       0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100      5.17G      1.103      1.682      1.171         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.532      0.467      0.377      0.191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      5.17G      0.964       1.51      1.097         19       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.444        0.4      0.382      0.186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100      5.17G     0.9578      1.604       1.11         28       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.662      0.522      0.439       0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      5.17G      1.003      1.579        1.1         18       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.916        0.4      0.488      0.203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      5.17G      1.037      1.796      1.182         22       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.713        0.4      0.459      0.201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100      5.17G     0.9728      1.526      1.111         26       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.518      0.467      0.458      0.214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100      5.17G     0.9658      1.495      1.108         26       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.562      0.333      0.454      0.207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      5.17G     0.9541      1.368      1.086         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.809      0.333      0.446      0.196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100      5.17G     0.9748      1.425      1.156         22       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.953      0.333      0.446      0.202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100      5.17G      0.929      1.349      1.069         23       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.964      0.333      0.461      0.202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100      5.17G      0.887      1.387      1.039         17       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.94      0.333      0.501      0.205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100      5.17G      0.928       1.45      1.076         18       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.856      0.397      0.508      0.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      5.17G     0.8974      1.331      1.082         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.854       0.39      0.521      0.232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100      5.17G     0.8934      1.279      1.074         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.595      0.467      0.489      0.216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      5.17G     0.8288      1.263      1.045         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.578      0.467      0.492      0.208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100      5.17G     0.8393      1.211      1.024         29       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.803      0.333      0.445      0.222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100      5.17G     0.7929      1.218      1.023         21       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.922      0.333       0.47       0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100      5.17G     0.7913      1.239      1.005         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.803      0.333      0.467      0.217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100      5.17G     0.8292      1.123          1         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.561      0.427      0.452      0.204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100      5.17G     0.8666        1.2      1.019         27       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.616      0.467      0.461      0.209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100      5.17G     0.7878      1.109     0.9822         25       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.594      0.467      0.466      0.222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100      5.17G      0.809      1.227      1.024         18       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.534      0.467      0.472      0.227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100      5.17G     0.7436        1.1      1.031         22       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.574      0.467      0.464      0.216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100      5.17G     0.8524       1.18      1.049         17       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.778        0.4      0.459       0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100      5.17G     0.7232      1.096      1.016         34       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.81      0.467      0.463      0.205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100      5.17G     0.7899      1.219      1.043         20       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.916      0.467      0.476      0.232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100      5.17G     0.7025      1.088     0.9557         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.784      0.467      0.487      0.223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100      5.17G     0.7112      1.024     0.9721         30       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15          1      0.391      0.489      0.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100      5.17G     0.6926      1.011     0.9862         19       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.551      0.467      0.483      0.222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100      5.17G     0.6501      1.043     0.9639         24       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.595      0.533      0.486      0.236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100      5.17G     0.7393      1.103     0.9834         18       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.604       0.51      0.495      0.239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100      5.17G     0.6802      1.056     0.9572         19       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.67      0.407      0.501      0.235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100      5.17G     0.7568       1.26      1.003         14       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.824        0.4      0.506      0.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100      5.17G     0.6488      1.187     0.9244         12       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15          1      0.398      0.512      0.253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100      5.17G     0.6525      1.203     0.9202         11       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.979        0.4      0.519      0.238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100      5.17G     0.6325      1.153     0.9285         14       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.975        0.4      0.516      0.247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100      5.17G     0.5593      1.101     0.9123         14       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15       0.98        0.4      0.522      0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100      5.17G      0.601      1.221     0.8651         15       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15          1      0.333      0.487      0.256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100      5.17G     0.6097      1.109     0.9128         14       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.804        0.4      0.501       0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100      5.17G     0.6031      1.123     0.9008         13       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.819        0.4      0.491      0.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100      5.17G     0.5859      1.083     0.8772         17       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.824        0.4       0.49      0.235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100      5.17G     0.5741      1.118     0.9102         15       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15      0.827        0.4      0.492      0.235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "100 epochs completed in 0.127 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15          1      0.333      0.487      0.255\n",
            "Speed: 0.5ms preprocess, 4.6ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLO_sech_1/val/labels.cache... 16 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         16         15          1      0.333      0.487      0.257\n",
            "Speed: 0.5ms preprocess, 9.6ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train42\u001b[0m\n",
            "0.2565677758457197\n",
            "0.48699333380722054\n",
            "0.14321709852700806\n",
            "[    0.25657]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_name = 'img1.jpg'\n",
        "img = cv2.imread(img_name)"
      ],
      "metadata": {
        "id": "UzDq9cZBdJLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(img_name)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrgADbOocEtl",
        "outputId": "54eb14e3-6ae9-478d-e742-4a98c2c86353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/img1.jpg: 768x1024 1 cancer, 11.8ms\n",
            "Speed: 9.4ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 768, 1024)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'cancer'}\n",
              " obb: None\n",
              " orig_img: array([[[ 89,  72,  59],\n",
              "         [ 89,  72,  59],\n",
              "         [ 89,  72,  59],\n",
              "         ...,\n",
              "         [ 89,  72,  59],\n",
              "         [ 89,  72,  59],\n",
              "         [ 89,  72,  59]],\n",
              " \n",
              "        [[ 85,  68,  55],\n",
              "         [ 85,  68,  55],\n",
              "         [ 85,  68,  55],\n",
              "         ...,\n",
              "         [ 85,  68,  55],\n",
              "         [ 85,  68,  55],\n",
              "         [ 85,  68,  55]],\n",
              " \n",
              "        [[ 82,  65,  52],\n",
              "         [ 82,  65,  52],\n",
              "         [ 82,  65,  52],\n",
              "         ...,\n",
              "         [ 82,  65,  52],\n",
              "         [ 82,  65,  52],\n",
              "         [ 82,  65,  52]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [ 50,  50,  50],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  1,   1,   1],\n",
              "         [ 79, 192,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [ 79, 192,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (873, 1164)\n",
              " path: '/content/img1.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/train43'\n",
              " speed: {'preprocess': 9.436607360839844, 'inference': 11.782407760620117, 'postprocess': 2.074003219604492}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment anything initial masks"
      ],
      "metadata": {
        "id": "nTlkvJXC62Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n"
      ],
      "metadata": {
        "id": "YJNYfmiG7WdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/segment-anything.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOGjo2kX6_r2",
        "outputId": "d672df7d-a02b-4f3f-d555-1a86260be7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-4oplwjdv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-4oplwjdv\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment_anything\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=5bc211d84108c100eb024bdde4b9440b6984b914466ea4c5b19e71e6288c4fbb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pizsoc_9/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment_anything\n",
            "Installing collected packages: segment_anything\n",
            "Successfully installed segment_anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_type = \"vit_b\"  # \"vit_b\" –∏–ª–∏ \"vit_l\" –¥–ª—è –¥—Ä—É–≥–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤\n",
        "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "image_path = \"img1.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "print(image.shape)\n",
        "\n",
        "predictor.set_image(image)\n",
        "\n",
        "image_embedding = predictor.get_image_embedding()\n",
        "\n",
        "print(\"Image Embedding Shape:\", image_embedding.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdQvPPdR7uuL",
        "outputId": "10c38101-c861-447c-cd11-65cdcf1a3db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(873, 1164, 3)\n",
            "Image Embedding Shape: torch.Size([1, 256, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import torch\n",
        "\n",
        "embedding_flat = image_embedding.cpu().detach().numpy().reshape(-1, image_embedding.shape[1])  # (N, C)\n",
        "\n",
        "n_clusters = 5\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(embedding_flat)\n",
        "labels = kmeans.labels_.reshape(image_embedding.shape[2], image_embedding.shape[3])  # (H/16, W/16)\n",
        "\n",
        "plt.imshow(labels, cmap='tab20')\n",
        "plt.title(\"Initial Segmentation Areas\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "c9cPYQ_89Ju9",
        "outputId": "34763c5f-9898-42e1-b6cf-35a4354d0c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=1.5, min_samples=10, metric='euclidean')  # eps –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
        "labels = dbscan.fit_predict(embedding_flat)\n",
        "\n",
        "labels_image = labels.reshape(64, 64)\n",
        "\n",
        "plt.imshow(labels_image, cmap='tab10')\n",
        "plt.title(\"–ö–ª–∞—Å—Ç–µ—Ä—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º DBSCAN\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "36uNtPYmBPcD",
        "outputId": "f488f0fc-e3a4-4a77-e53f-aa822f45c6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}